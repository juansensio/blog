{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/117_langchain/117_langchain.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain ü¶úüîó"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la incre√≠ble adopci√≥n de los modelos de lenguaje que estamos viviendo en este momento cientos de nuevas herramientas y aplicaciones est√°n apareciendo para aprovechar el poder de estas redes neuronales. Una de ellas parece destacar por encima del resto, y √©sta es [LangChain](https://docs.langchain.com/docs/). En este post vamos a ver qu√© es y c√≥mo podemos usarla."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es LangChain?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg√∫n su [documentaci√≥n](https://docs.langchain.com/docs/), Langchain es un entorno de desarrollo de aplicaciones basadas en modelos de lenguajes. Las herramientas proporcionadas por LangChain permiten, por un lado, conectar modelos de lenguaje con otras fuentes de datos (como por ejemplo tus porpios documentos, bases de datos o emails) y, por otro lado, permiten a estos modelos interactuar con su entorno (por ejemplo, enviando emails o llamando a APIs web). Langchain ofrece librer√≠as en Python y Javascript para facilitar el desarrollo de estas aplicaciones, en este post nos centraremos en la librer√≠a de Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chateando con un documento PDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver un ejemplo pr√°ctico de c√≥mo usar LangChain para proporcionar informaci√≥n sobre un documento PDF, lo cual nos permitir√° para descubrir los diferentes componentes y funcionalidades de LangChain.\n",
    "\n",
    "> Vamos a usar como documento el art√≠culo [On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547.pdf), de Fran√ßois Chollet (2019)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que necesitamos es instalar la librer√≠a de LangChain. En funci√≥n de las herramientas que quieras usar, deber√°s instalar las dependencias necesarias. \n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.160'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continucaci√≥n, necesitaremos un modelo. LangChain ofrece integraciones con multitud de [modelos](https://python.langchain.com/en/latest/modules/models/llms/integrations.html) de lenguaje existentes, tanto en local como en remoto accesibles a trav√©s de API (como los modelos de OpenAI). En este ejemplo usaremos la integraci√≥n con [Huggingface](https://huggingface.co/) para usar el modelo en local, pero si est√°s desarrollando una aplicaci√≥n en producci√≥n probablemente quieras usar un modelo remoto como GPT-4.\n",
    "\n",
    "> Si quieres usar los modelos de OpenAI, como GPT-4, necesitar√°s una API key (por lo que te cobrar√°n por cada vez que lo uses).\n",
    "\n",
    "En este ejemplo usaremos el modelo [OpenAssistant/stablelm-7b-sft-v7-epoch-3](https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3), un modelo de lenguaje abierto y que puedo ejecutar en mis dos GPUs. Si no dispones de GPUs puedes ejecutar el modelo en CPU, pero el proceso ser√° m√°s lento. Alternativamente, puedes usar modelos m√°s peque√±os.\n",
    "\n",
    "> El soporte multi-gpu en LangChain no es muy estable ahora mismo üòû"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0349fe0aa34c40fa83d269b4df0bd995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 2 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "# OJO! max_length tiene que ser suficiente como para tener el documento (chuck) + el prompt + el system prompt + respuesta generada !!!\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"OpenAssistant/stablelm-7b-sft-v7-epoch-3\", task=\"text-generation\", model_kwargs={\"temperature\": 0.0, \"max_length\": 2048, 'device_map': 'auto'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente elemento que LangChain nos ofrece es el [`prompt`](https://python.langchain.com/en/latest/modules/prompts.html), que es el texto que le pasaremos al modelo para que siga generando. Para ello podemos definir una plantilla con el texto que queremos que aparezca en el prompt y los placeholders que podremos inyectar mediante variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"<|prompter|>{question}<|endoftext|><|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos nuestro modelo y prompt, podemos crear nuestra primera [`chain`](https://python.langchain.com/en/latest/modules/chains.html). Este es uno de los elementos principales en LangChain, y representa una secuencia de operaciones que se ejecutar√°n en orden. El siguiente ejemplo encadena el prompt con el modelo para generar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (2048) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1405: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The meaning of life is a question that has puzzled philosophers and theologians for centuries, and there is no one answer that is universally accepted. Many people believe that the meaning of life is to seek happiness and fulfillment, to achieve personal goals and dreams, and to make the world a better place for oneself and others. Others believe that the meaning of life is to find a connection with a higher power or a divine presence, and to use that connection to guide one's actions and decisions. Ultimately, the meaning of life is a deeply personal question, and each individual must find their own answer based on their own beliefs and experiences.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is the meaning of life?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible crear cadenas que contengan otras cadenas, permitiendo el desarrollo de aplicaciones tipo [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT) en el que diferentes modelos se alimentan entre si para llevar a cabo tareas complejas. Puede ver ejemplos de cadenas en la [documentaci√≥n](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html#)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver c√≥mo podemos usar el modelo de lenguaje para extraer informaci√≥n de nuestro pdf. Para ello, LangChain ofrece funcionalidad para cargar [documentos](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html) en m√∫ltiples formatos. En nuestro caso, cargarmos un pdf usando su url p√∫blica de arxiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import OnlinePDFLoader\n",
    "\n",
    "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/1911.01547.pdf\")\n",
    "document = loader.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma en la que podemos usar un modelo de lenguaje para extraer informaci√≥n de un documento es pas√°ndole el contenido del documento como contexto, como parte del prompt. En el caso de un documento corto, como por ejemplo un post o un email, podemos pasar el documento entero como contexto. En el caso de un documento largo, como un libro o un pdf grande como el del ejemplo, es posible que no podamos pasar el documento entero ya que la cantidad de tokens que podemos pasar al modelo es limitada. \n",
    "\n",
    "> Una de las grandes ventajas de GPT-4 es que es capaz de admitir contextos de hasta 64k tokens ü§Ø. Sin embargo, muchos de los modelos disponnibles no superan los pocos miles de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As√≠ pues, para poder llevar a cabo nuestro objetivo, tendremos que generar diferentes trozos de nuestro documento, diferentes `chunks`. De nuevo, LangChain nos ofrece funcionalidad para ello con sus [text splitters](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1995, which is longer than the specified 1024\n",
      "Created a chunk of size 1435, which is longer than the specified 1024\n",
      "Created a chunk of size 1167, which is longer than the specified 1024\n",
      "Created a chunk of size 1342, which is longer than the specified 1024\n",
      "Created a chunk of size 1037, which is longer than the specified 1024\n",
      "Created a chunk of size 1484, which is longer than the specified 1024\n",
      "Created a chunk of size 1057, which is longer than the specified 1024\n",
      "Created a chunk of size 1044, which is longer than the specified 1024\n",
      "Created a chunk of size 1120, which is longer than the specified 1024\n",
      "Created a chunk of size 1268, which is longer than the specified 1024\n",
      "Created a chunk of size 1464, which is longer than the specified 1024\n",
      "Created a chunk of size 1898, which is longer than the specified 1024\n",
      "Created a chunk of size 1066, which is longer than the specified 1024\n",
      "Created a chunk of size 1506, which is longer than the specified 1024\n",
      "Created a chunk of size 1270, which is longer than the specified 1024\n",
      "Created a chunk of size 1309, which is longer than the specified 1024\n",
      "Created a chunk of size 1160, which is longer than the specified 1024\n",
      "Created a chunk of size 1121, which is longer than the specified 1024\n",
      "Created a chunk of size 1060, which is longer than the specified 1024\n",
      "Created a chunk of size 1103, which is longer than the specified 1024\n",
      "Created a chunk of size 1164, which is longer than the specified 1024\n",
      "Created a chunk of size 1319, which is longer than the specified 1024\n",
      "Created a chunk of size 1148, which is longer than the specified 1024\n",
      "Created a chunk of size 1119, which is longer than the specified 1024\n",
      "Created a chunk of size 1080, which is longer than the specified 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "\n",
    "# texts = text_splitter.split_text(raw_text)\n",
    "documents = text_splitter.split_documents(document)\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo se han generado 211 documentos de una longitud aproximada de 1024 tokens con un solapamiento de 64 tokens entre ellos para evitar que se pierda informaci√≥n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1Turing‚Äôs imitation game was largely meant as an argumentative device in a philosophical discussion, not as a literal test of intelligence. Mistaking it for a test representative of the goal of the Ô¨Åeld of AI has been an ongoing problem.\\n\\n3\\n\\nplicit deÔ¨Ånitions has been substituted with implicit deÔ¨Ånitions and biases that stretch back decades. Though invisible, these biases are still structuring many research efforts today, as illustrated by our Ô¨Åeld‚Äôs ongoing fascination with outperforming humans at board games or video games (a trend we discuss in I.3.5 and II.1). The goal of this document is to point out the implicit assumptions our Ô¨Åeld has been working from, correct some of its most salient biases, and provide an actionable formal deÔ¨Ånition and measurement benchmark for human-like general intelligence, leveraging modern insight from developmental cognitive psychology.\\n\\nI.2 DeÔ¨Åning intelligence: two divergent visions'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I.2 DeÔ¨Åning intelligence: two divergent visions\\n\\nLooked at in one way, everyone knows what intelligence is; looked at in another way, no one does.\\n\\nRobert J. Sternberg, 2000\\n\\nMany formal and informal deÔ¨Ånitions of intelligence have been proposed over the past few decades, although there is no existing scientiÔ¨Åc consensus around any single deÔ¨Ånition. Sternberg & Detterman noted in 1986 [87] that when two dozen prominent psychologists were asked to deÔ¨Åne intelligence, they all gave somewhat divergent answers. In the context of AI research, Legg and Hutter [53] summarized in 2007 no fewer than 70 deÔ¨Ånitions from the literature into a single statement: ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äù'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[11].page_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øC√≥mo podemos ahora saber qu√© trozo de texto le tendremos que pasar al modelo en el prompt? Para ello primero generaremos [embeddings](https://python.langchain.com/en/latest/modules/models/text_embedding.html) de cada documento, una representaci√≥n num√©rica en forma de vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.042428433895111084,\n",
       " 0.021917296573519707,\n",
       " -0.022802436724305153,\n",
       " 0.00871153362095356,\n",
       " -0.022152919322252274,\n",
       " 0.002340561244636774,\n",
       " 0.06916215270757675,\n",
       " 0.006181132048368454,\n",
       " 0.026825249195098877,\n",
       " 0.03189503774046898,\n",
       " 0.0245673730969429,\n",
       " 0.03437993675470352,\n",
       " 0.014492091722786427,\n",
       " 0.004250011872500181,\n",
       " 0.05395049229264259,\n",
       " -0.03422139212489128,\n",
       " 0.011204035952687263,\n",
       " -0.02136232703924179,\n",
       " 0.03636736422777176,\n",
       " 0.0029819831252098083,\n",
       " -0.08053704351186752,\n",
       " -0.032645463943481445,\n",
       " -0.017528465017676353,\n",
       " -0.0011793108424171805,\n",
       " 0.026897713541984558,\n",
       " -0.03333451598882675,\n",
       " 0.07448339462280273,\n",
       " -0.054355110973119736,\n",
       " 0.02542339265346527,\n",
       " -0.035657402127981186,\n",
       " -0.016151143237948418,\n",
       " 0.030895384028553963,\n",
       " -0.06922627985477448,\n",
       " 0.016754403710365295,\n",
       " 2.1454820853250567e-06,\n",
       " -0.04243779554963112,\n",
       " 0.012081843800842762,\n",
       " -0.0049616568721830845,\n",
       " -0.007090848870575428,\n",
       " 0.00020149094052612782,\n",
       " 0.025804489850997925,\n",
       " 0.07215629518032074,\n",
       " -0.0064743212424218655,\n",
       " 0.026002708822488785,\n",
       " -0.04068382829427719,\n",
       " 0.021893342956900597,\n",
       " -0.04979454725980759,\n",
       " -0.01748614013195038,\n",
       " -0.027759244665503502,\n",
       " -0.004340029787272215,\n",
       " 0.0163387693464756,\n",
       " 0.052752889692783356,\n",
       " 0.04543222486972809,\n",
       " -0.0420868843793869,\n",
       " 0.0474482960999012,\n",
       " 0.017135336995124817,\n",
       " 0.013530587777495384,\n",
       " 0.015604479238390923,\n",
       " -0.037800807505846024,\n",
       " -0.0006414337549358606,\n",
       " -0.01838819868862629,\n",
       " 0.007416424807161093,\n",
       " 0.023761199787259102,\n",
       " 0.0009100894094444811,\n",
       " -0.0023336804006248713,\n",
       " -0.022574346512556076,\n",
       " 0.05082284286618233,\n",
       " 0.006758802570402622,\n",
       " 0.017328370362520218,\n",
       " -0.03350646421313286,\n",
       " 0.039401113986968994,\n",
       " 0.043079063296318054,\n",
       " -0.011679540388286114,\n",
       " 0.07801881432533264,\n",
       " 0.038200266659259796,\n",
       " -0.005611011758446693,\n",
       " -0.0591573491692543,\n",
       " -0.0037992806173861027,\n",
       " 0.017212269827723503,\n",
       " -0.06335227191448212,\n",
       " -0.005054138600826263,\n",
       " 0.09362633526325226,\n",
       " -0.019540933892130852,\n",
       " 0.006837992928922176,\n",
       " 0.01239307876676321,\n",
       " 0.04372002184391022,\n",
       " 0.0411202646791935,\n",
       " 0.009136530570685863,\n",
       " 0.0021314541809260845,\n",
       " -0.03422268107533455,\n",
       " -0.010278603993356228,\n",
       " -0.04005831107497215,\n",
       " -0.03156764805316925,\n",
       " 0.022008981555700302,\n",
       " -0.01353748794645071,\n",
       " -0.036866046488285065,\n",
       " 0.058773696422576904,\n",
       " -0.04039543867111206,\n",
       " 0.015585060231387615,\n",
       " 0.00446684705093503,\n",
       " 0.028987059369683266,\n",
       " -0.011503680609166622,\n",
       " 0.06616102904081345,\n",
       " 0.03260771930217743,\n",
       " -0.01786023937165737,\n",
       " 0.08105886727571487,\n",
       " 0.01387537270784378,\n",
       " 0.07295790314674377,\n",
       " -0.03424039110541344,\n",
       " 0.030904319137334824,\n",
       " -0.04903272166848183,\n",
       " -0.019671525806188583,\n",
       " 0.013768781907856464,\n",
       " 0.0067288558930158615,\n",
       " 0.0736922025680542,\n",
       " -0.0003638851048890501,\n",
       " -0.06895644962787628,\n",
       " -0.03186299279332161,\n",
       " -0.05155569687485695,\n",
       " -0.006151876412332058,\n",
       " -0.08475222438573837,\n",
       " 0.0007959030917845666,\n",
       " 0.02343355305492878,\n",
       " -0.015619819052517414,\n",
       " -0.029298020526766777,\n",
       " 0.013465220108628273,\n",
       " -0.054084330797195435,\n",
       " 0.030025459825992584,\n",
       " -0.017719758674502373,\n",
       " 0.036285772919654846,\n",
       " -0.0014307086821645498,\n",
       " 0.021606385707855225,\n",
       " 0.014369389042258263,\n",
       " 0.015527244657278061,\n",
       " 0.0174411628395319,\n",
       " 0.07699459046125412,\n",
       " 0.024510810151696205,\n",
       " -0.05208544433116913,\n",
       " 0.02263828180730343,\n",
       " -0.02844151481986046,\n",
       " 0.03891596570611,\n",
       " -0.027156315743923187,\n",
       " 0.027960525825619698,\n",
       " -0.04989313334226608,\n",
       " 0.0091232405975461,\n",
       " 0.03031116910278797,\n",
       " 0.01725529320538044,\n",
       " -0.06402545422315598,\n",
       " -0.017896538600325584,\n",
       " -0.016482030972838402,\n",
       " -0.0016021813498809934,\n",
       " -0.01672859862446785,\n",
       " -0.010942147113382816,\n",
       " 0.02017894759774208,\n",
       " 0.03725812956690788,\n",
       " 0.04569023475050926,\n",
       " -0.01632027141749859,\n",
       " 0.02901189588010311,\n",
       " 0.051333535462617874,\n",
       " -0.043196290731430054,\n",
       " 0.042616408318281174,\n",
       " 0.0018624187214300036,\n",
       " 0.03411070257425308,\n",
       " -0.015388497151434422,\n",
       " -0.002338588936254382,\n",
       " -0.008565631695091724,\n",
       " 0.015155671164393425,\n",
       " 0.0007072649314068258,\n",
       " -0.014780380763113499,\n",
       " -0.0023071079049259424,\n",
       " 0.012245852500200272,\n",
       " 0.0003863033780362457,\n",
       " -0.017516782507300377,\n",
       " 0.03541883826255798,\n",
       " 0.029698876664042473,\n",
       " 0.08912410587072372,\n",
       " 0.007493190001696348,\n",
       " 0.06134864315390587,\n",
       " -0.02572980523109436,\n",
       " -0.009838719852268696,\n",
       " 0.03711853176355362,\n",
       " 0.030292227864265442,\n",
       " -0.024539966136217117,\n",
       " 0.06445667147636414,\n",
       " -0.05022129788994789,\n",
       " 0.008100890554487705,\n",
       " 0.012973200529813766,\n",
       " 0.04124484956264496,\n",
       " -0.028575345873832703,\n",
       " -0.04398837313055992,\n",
       " 0.004807096906006336,\n",
       " 0.011071735061705112,\n",
       " 0.039958417415618896,\n",
       " -0.002152225701138377,\n",
       " 0.03212736174464226,\n",
       " -0.017465785145759583,\n",
       " 0.004690490197390318,\n",
       " -0.08366812020540237,\n",
       " -0.0060553522780537605,\n",
       " -0.01742875762283802,\n",
       " -0.03682151809334755,\n",
       " -0.044182129204273224,\n",
       " 0.044990140944719315,\n",
       " -0.00223426497541368,\n",
       " -0.01937187649309635,\n",
       " -0.012247228994965553,\n",
       " 0.029757404699921608,\n",
       " 0.01567136123776436,\n",
       " 0.009749731048941612,\n",
       " -0.014318820089101791,\n",
       " 0.019415076822042465,\n",
       " -0.023940859362483025,\n",
       " 0.015712380409240723,\n",
       " -0.010775727219879627,\n",
       " -0.01544976606965065,\n",
       " -0.00935679767280817,\n",
       " 0.03190509229898453,\n",
       " 0.0010286347242072225,\n",
       " -0.02718617394566536,\n",
       " 0.02475859597325325,\n",
       " 0.0229136161506176,\n",
       " 0.016477808356285095,\n",
       " -0.01178506575524807,\n",
       " -0.017795434221625328,\n",
       " -0.02970249205827713,\n",
       " -0.011355696246027946,\n",
       " -0.05380289629101753,\n",
       " -0.00626777671277523,\n",
       " 0.04816697537899017,\n",
       " -0.005663651507347822,\n",
       " 0.0033230220433324575,\n",
       " 0.010074436664581299,\n",
       " 0.0008955656085163355,\n",
       " -0.04619889706373215,\n",
       " -0.025289906188845634,\n",
       " 0.0006988139939494431,\n",
       " 0.042980995029211044,\n",
       " 0.09424527734518051,\n",
       " -0.016090968623757362,\n",
       " -0.08228619396686554,\n",
       " 0.023807343095541,\n",
       " 0.028340764343738556,\n",
       " 0.056066930294036865,\n",
       " 0.01065574586391449,\n",
       " 0.029036857187747955,\n",
       " -0.033961597830057144,\n",
       " 0.020748797804117203,\n",
       " 0.03465970605611801,\n",
       " 0.034580446779727936,\n",
       " -0.04662863910198212,\n",
       " -0.008100048638880253,\n",
       " 0.0014700971078127623,\n",
       " 0.04313179850578308,\n",
       " -0.014898166991770267,\n",
       " 0.06721469014883041,\n",
       " -0.01485687680542469,\n",
       " -0.053689271211624146,\n",
       " 0.06143486499786377,\n",
       " -0.009497793391346931,\n",
       " 0.05103262513875961,\n",
       " -0.07163570076227188,\n",
       " -0.02565235085785389,\n",
       " 0.012127438560128212,\n",
       " -0.0010270668426528573,\n",
       " 0.0680384635925293,\n",
       " -0.02102489583194256,\n",
       " -0.032660890370607376,\n",
       " -0.039356082677841187,\n",
       " -0.015211116522550583,\n",
       " -0.006445730105042458,\n",
       " 0.03529757261276245,\n",
       " -0.022383231669664383,\n",
       " -0.02127823419868946,\n",
       " -0.013188740238547325,\n",
       " 0.022730112075805664,\n",
       " 0.007785457652062178,\n",
       " 0.00871283933520317,\n",
       " 0.05328071489930153,\n",
       " 0.01385223027318716,\n",
       " 0.02184681035578251,\n",
       " -0.029649987816810608,\n",
       " -0.024348359555006027,\n",
       " -0.008121343329548836,\n",
       " -0.02077687904238701,\n",
       " -0.045156702399253845,\n",
       " 0.04005135968327522,\n",
       " 0.04502709582448006,\n",
       " 0.03718961030244827,\n",
       " 0.04122551903128624,\n",
       " -0.024562159553170204,\n",
       " -0.0725952535867691,\n",
       " -0.0031718790996819735,\n",
       " -0.02453957125544548,\n",
       " -0.02887248620390892,\n",
       " 0.04252193495631218,\n",
       " 0.009079045616090298,\n",
       " 0.004776453133672476,\n",
       " 0.07285772264003754,\n",
       " 0.05086898058652878,\n",
       " 0.022919749841094017,\n",
       " 0.0209369994699955,\n",
       " 0.007015296258032322,\n",
       " -0.003926412668079138,\n",
       " -0.0051567587070167065,\n",
       " 0.004334837198257446,\n",
       " 0.06529965996742249,\n",
       " -0.03959586098790169,\n",
       " -0.07515786588191986,\n",
       " -0.02563089318573475,\n",
       " 0.04620395973324776,\n",
       " -0.00944729708135128,\n",
       " -0.013517516665160656,\n",
       " 0.016584059223532677,\n",
       " 0.11240947246551514,\n",
       " -0.04313912242650986,\n",
       " -0.02673254907131195,\n",
       " -0.03581554442644119,\n",
       " -0.005891126114875078,\n",
       " -0.005145467352122068,\n",
       " 0.08514262735843658,\n",
       " -0.00161155650857836,\n",
       " -0.01827416568994522,\n",
       " -0.012182967737317085,\n",
       " 0.007303033955395222,\n",
       " 0.03487453982234001,\n",
       " -0.01864047907292843,\n",
       " -0.006255438085645437,\n",
       " 0.016190558671951294,\n",
       " 0.06608130037784576,\n",
       " 0.008630632422864437,\n",
       " 0.00807118695229292,\n",
       " -0.0818367525935173,\n",
       " -0.022953219711780548,\n",
       " -0.07775412499904633,\n",
       " 0.011124569922685623,\n",
       " 0.0009097906877286732,\n",
       " -0.04927006736397743,\n",
       " 0.012677040882408619,\n",
       " -0.0034344817977398634,\n",
       " -0.05543562024831772,\n",
       " -0.011463555507361889,\n",
       " -0.0016890841070562601,\n",
       " -0.013546567410230637,\n",
       " 0.055983468890190125,\n",
       " -0.002838516142219305,\n",
       " 0.005879160016775131,\n",
       " 0.06408818066120148,\n",
       " -0.08111601322889328,\n",
       " -0.01833459921181202,\n",
       " -0.05365920066833496,\n",
       " 0.05541064962744713,\n",
       " -0.0022177151404321194,\n",
       " -0.0046323733404278755,\n",
       " -0.014942334964871407,\n",
       " 0.023122690618038177,\n",
       " -0.03360643610358238,\n",
       " 0.012761413119733334,\n",
       " 0.03977229818701744,\n",
       " 0.02249441295862198,\n",
       " -0.0664202868938446,\n",
       " 0.027522822842001915,\n",
       " 0.030301539227366447,\n",
       " -0.03587955981492996,\n",
       " 0.02627977356314659,\n",
       " 0.05300137400627136,\n",
       " 0.007403489202260971,\n",
       " 0.031087419018149376,\n",
       " 0.00799115002155304,\n",
       " -0.0005928006139583886,\n",
       " 0.01165710762143135,\n",
       " 0.03588023781776428,\n",
       " -0.024520892649888992,\n",
       " -0.0005685655632987618,\n",
       " 0.0617319755256176,\n",
       " 0.022378452122211456,\n",
       " 0.008967682719230652,\n",
       " 0.009773782454431057,\n",
       " 0.012384576722979546,\n",
       " -0.04214940965175629,\n",
       " 0.019479766488075256,\n",
       " 0.04215407744050026,\n",
       " -0.003458331571891904,\n",
       " 0.03827850520610809,\n",
       " -0.015465918928384781,\n",
       " 0.013191282749176025,\n",
       " -0.042876947671175,\n",
       " -0.03986087441444397,\n",
       " 0.001559645519591868,\n",
       " -0.05138785019516945,\n",
       " -0.02728741057217121,\n",
       " 0.013203498907387257,\n",
       " -0.04842260479927063,\n",
       " -0.06309276819229126,\n",
       " 0.02257339470088482,\n",
       " -0.0036499497946351767,\n",
       " 0.011787904426455498,\n",
       " -0.03823432698845863,\n",
       " -0.01874575763940811,\n",
       " 0.013034265488386154,\n",
       " 0.025951562449336052,\n",
       " -0.020541736856102943,\n",
       " -0.03970712050795555,\n",
       " 0.011245784349739552,\n",
       " 0.049191031605005264,\n",
       " -0.004471056628972292,\n",
       " -0.0030435393564403057,\n",
       " 0.016788741573691368,\n",
       " 0.0021017766557633877,\n",
       " -0.052719846367836,\n",
       " -0.0869712084531784,\n",
       " -0.05210992693901062,\n",
       " -0.011021877638995647,\n",
       " -0.034460850059986115,\n",
       " 0.02376578003168106,\n",
       " 0.054407160729169846,\n",
       " -0.01599309593439102,\n",
       " 0.013043244369328022,\n",
       " -0.08141595125198364,\n",
       " -0.012950657866895199,\n",
       " 0.0523710697889328,\n",
       " 0.012256891466677189,\n",
       " 0.0738392099738121,\n",
       " 0.015034962445497513,\n",
       " 0.04568178579211235,\n",
       " -0.039820216596126556,\n",
       " -0.013231255114078522,\n",
       " -0.02016032300889492,\n",
       " -0.016321809962391853,\n",
       " 0.044918492436409,\n",
       " 0.00931740365922451,\n",
       " -0.01526579074561596,\n",
       " 0.021103912964463234,\n",
       " -0.033639080822467804,\n",
       " -0.0076798079535365105,\n",
       " -0.05640054866671562,\n",
       " -0.08669667690992355,\n",
       " 0.03746683895587921,\n",
       " 0.058438144624233246,\n",
       " -0.009952529333531857,\n",
       " -0.05949240177869797,\n",
       " -0.020573487505316734,\n",
       " 0.011054917238652706,\n",
       " 0.07883378863334656,\n",
       " 0.013713439926505089,\n",
       " -0.057617027312517166,\n",
       " -0.041707463562488556,\n",
       " 0.003870623419061303,\n",
       " -0.028811248019337654,\n",
       " -0.00923179555684328,\n",
       " 0.038332950323820114,\n",
       " -0.025764409452676773,\n",
       " -0.07003835588693619,\n",
       " -0.024943353608250618,\n",
       " -0.03374570235610008,\n",
       " -0.008777189068496227,\n",
       " -0.041931577026844025,\n",
       " -0.021163642406463623,\n",
       " 0.01738256774842739,\n",
       " 0.009197072125971317,\n",
       " 0.03026701509952545,\n",
       " 0.06486044079065323,\n",
       " 0.03625648096203804,\n",
       " -0.04757491871714592,\n",
       " -0.011054955422878265,\n",
       " 0.021443895995616913,\n",
       " 0.057599786669015884,\n",
       " -0.033056557178497314,\n",
       " -0.008982429280877113,\n",
       " 0.053412530571222305,\n",
       " -0.007407221477478743,\n",
       " -0.039063651114702225,\n",
       " -0.012755775824189186,\n",
       " -0.012069475837051868,\n",
       " -0.019288333132863045,\n",
       " 0.06303532421588898,\n",
       " -0.01627287082374096,\n",
       " 0.022932594642043114,\n",
       " -0.04599475488066673,\n",
       " -0.030406421050429344,\n",
       " -0.017856448888778687,\n",
       " -0.0016631691250950098,\n",
       " 0.0410953015089035,\n",
       " 0.022726871073246002,\n",
       " 0.00373634765855968,\n",
       " 0.018694838508963585,\n",
       " -0.03657865524291992,\n",
       " -0.0327138788998127,\n",
       " -0.040842942893505096,\n",
       " -0.00199104193598032,\n",
       " -0.05034726485610008,\n",
       " -0.011557899415493011,\n",
       " 0.019512630999088287,\n",
       " 0.00035516227944754064,\n",
       " -0.011522638611495495,\n",
       " 0.02351081557571888,\n",
       " -0.0353330560028553,\n",
       " -0.04045310243964195,\n",
       " 0.020759789273142815,\n",
       " -0.06381755322217941,\n",
       " 0.0024805571883916855,\n",
       " -0.02490331418812275,\n",
       " 0.012920038774609566,\n",
       " -0.01181876752525568,\n",
       " -0.0027563399635255337,\n",
       " -0.021379949524998665,\n",
       " 0.06124720722436905,\n",
       " 0.05307488888502121,\n",
       " 0.056450389325618744,\n",
       " -0.017626477405428886,\n",
       " 0.010454977862536907,\n",
       " -0.017012430354952812,\n",
       " 0.013661478646099567,\n",
       " -0.08164993673563004,\n",
       " -0.07599493116140366,\n",
       " 0.01500437781214714,\n",
       " 0.061387158930301666,\n",
       " -0.04749169945716858,\n",
       " 0.024458354339003563,\n",
       " -0.0003442251472733915,\n",
       " -0.026560675352811813,\n",
       " -0.005136502906680107,\n",
       " -0.007950461469590664,\n",
       " -0.03532103821635246,\n",
       " -0.010742045938968658,\n",
       " -0.01616368070244789,\n",
       " 0.012423012405633926,\n",
       " 0.019486969336867332,\n",
       " 0.04139144718647003,\n",
       " 0.013941995799541473,\n",
       " 0.02559857815504074,\n",
       " -0.046188224107027054,\n",
       " -0.0017768616089597344,\n",
       " -0.05064672231674194,\n",
       " -0.03028124012053013,\n",
       " -0.03214281424880028,\n",
       " 0.006397570483386517,\n",
       " -0.015679016709327698,\n",
       " 0.04319603741168976,\n",
       " 0.0054560271091759205,\n",
       " 0.0223242174834013,\n",
       " -0.08210384100675583,\n",
       " -0.02873048558831215,\n",
       " 0.005243183579295874,\n",
       " 0.04169631376862526,\n",
       " 0.062133513391017914,\n",
       " 0.05606953799724579,\n",
       " -0.05464650318026543,\n",
       " 0.03240041807293892,\n",
       " -0.03195422515273094,\n",
       " -0.026756832376122475,\n",
       " 0.019266938790678978,\n",
       " -0.025984346866607666,\n",
       " -0.11428169161081314,\n",
       " -0.03434520214796066,\n",
       " -0.018005527555942535,\n",
       " -6.312893963439214e-33,\n",
       " -0.0450940802693367,\n",
       " -0.05250616744160652,\n",
       " 0.028054406866431236,\n",
       " 0.009557393379509449,\n",
       " 0.018755489960312843,\n",
       " -0.015453815460205078,\n",
       " -0.024716347455978394,\n",
       " 0.0515008307993412,\n",
       " -0.10441869497299194,\n",
       " -0.002256091684103012,\n",
       " 0.011639880016446114,\n",
       " 0.012247978709638119,\n",
       " -0.012129748240113258,\n",
       " -0.035054080188274384,\n",
       " 0.04272843152284622,\n",
       " 0.04838104173541069,\n",
       " -0.02512679249048233,\n",
       " -0.012643055059015751,\n",
       " -0.0361170768737793,\n",
       " -0.016646305099129677,\n",
       " 0.022493578493595123,\n",
       " -0.03482046723365784,\n",
       " 0.024507764726877213,\n",
       " -0.04803074151277542,\n",
       " 0.016946859657764435,\n",
       " -0.02961522340774536,\n",
       " 0.041624002158641815,\n",
       " -0.004760352894663811,\n",
       " 0.00041644638986326754,\n",
       " -0.0066285524517297745,\n",
       " -0.00628865510225296,\n",
       " 0.00848560594022274,\n",
       " 0.038584090769290924,\n",
       " -0.018537329509854317,\n",
       " 0.007618745788931847,\n",
       " -0.010238642804324627,\n",
       " 0.0011861860984936357,\n",
       " -0.06010822951793671,\n",
       " -0.01671995408833027,\n",
       " -0.05370962619781494,\n",
       " -0.035542819648981094,\n",
       " -0.08114311844110489,\n",
       " -0.006919261999428272,\n",
       " 0.018321922048926353,\n",
       " -0.04533511772751808,\n",
       " -0.09301376342773438,\n",
       " 0.060383141040802,\n",
       " 0.02190662920475006,\n",
       " 0.00976715236902237,\n",
       " -0.006921346299350262,\n",
       " -0.014439420774579048,\n",
       " -0.005221967119723558,\n",
       " -0.06409712880849838,\n",
       " -0.005481609608978033,\n",
       " -0.06685719639062881,\n",
       " -0.0315496064722538,\n",
       " 0.012172588147222996,\n",
       " -0.062045618891716,\n",
       " -0.0033498466946184635,\n",
       " 0.05497702211141586,\n",
       " -0.022847874090075493,\n",
       " 0.019785787910223007,\n",
       " -0.01934589445590973,\n",
       " -0.029325181618332863,\n",
       " 0.012668311595916748,\n",
       " 0.04058854654431343,\n",
       " 0.07340066134929657,\n",
       " -0.005959764588624239,\n",
       " 0.02800438366830349,\n",
       " -0.045415110886096954,\n",
       " 0.0503728985786438,\n",
       " 0.03640269860625267,\n",
       " 0.07774827629327774,\n",
       " -0.01883533038198948,\n",
       " 0.030350739136338234,\n",
       " -0.03613724187016487,\n",
       " -0.018418708816170692,\n",
       " -0.01170392893254757,\n",
       " 0.049760203808546066,\n",
       " 0.01197507418692112,\n",
       " -0.04082489013671875,\n",
       " -0.0408179946243763,\n",
       " -0.0628589317202568,\n",
       " 0.012191547080874443,\n",
       " 0.04233550280332565,\n",
       " -0.03165019303560257,\n",
       " -0.00418207747861743,\n",
       " -0.00026376164169050753,\n",
       " 0.03362196683883667,\n",
       " -0.020561370998620987,\n",
       " 0.0491233728826046,\n",
       " -0.026474634185433388,\n",
       " 0.02950422093272209,\n",
       " -0.0008996995748020709,\n",
       " 0.02518259361386299,\n",
       " 0.011100875213742256,\n",
       " 0.008545435033738613,\n",
       " 0.021445542573928833,\n",
       " 0.011861991137266159,\n",
       " -0.007478420156985521,\n",
       " -0.0007944543613120914,\n",
       " -0.00307196332141757,\n",
       " 0.007573411334306002,\n",
       " 0.030808942392468452,\n",
       " 0.0730031356215477,\n",
       " -0.013022033497691154,\n",
       " 0.014975006692111492,\n",
       " -0.004589396063238382,\n",
       " -0.02980535291135311,\n",
       " -0.0413300059735775,\n",
       " 0.019036857411265373,\n",
       " -0.008445210754871368,\n",
       " 0.054526958614587784,\n",
       " -0.05789851397275925,\n",
       " 0.0013897453900426626,\n",
       " -0.03895018249750137,\n",
       " 0.0075406264513731,\n",
       " -0.0976463034749031,\n",
       " -0.006434423848986626,\n",
       " -0.014813036657869816,\n",
       " -0.04631038010120392,\n",
       " 0.017373621463775635,\n",
       " -0.03176132217049599,\n",
       " -0.01791747286915779,\n",
       " 0.003365265903994441,\n",
       " -0.0074028861708939075,\n",
       " -0.003434208920225501,\n",
       " -0.01794513873755932,\n",
       " -0.048954714089632034,\n",
       " -0.011588345281779766,\n",
       " -0.010030721314251423,\n",
       " -0.0193816889077425,\n",
       " 2.796352873701835e-07,\n",
       " -0.02488102950155735,\n",
       " 0.048646312206983566,\n",
       " -0.032532449811697006,\n",
       " -0.03346394747495651,\n",
       " -0.007331342902034521,\n",
       " 0.000541206041816622,\n",
       " -0.050096698105335236,\n",
       " 0.024445926770567894,\n",
       " 0.056819651275873184,\n",
       " 0.04970882087945938,\n",
       " -0.00012975753634236753,\n",
       " -0.0018227319233119488,\n",
       " -0.004759395495057106,\n",
       " -0.0200379379093647,\n",
       " 0.019428109750151634,\n",
       " -0.05082065612077713,\n",
       " 0.024241358041763306,\n",
       " 0.035798996686935425,\n",
       " 0.0012674143072217703,\n",
       " 0.010406100191175938,\n",
       " 0.059430576860904694,\n",
       " -0.06527379900217056,\n",
       " 0.01743796095252037,\n",
       " 0.01288262102752924,\n",
       " -0.005201555322855711,\n",
       " -0.07089811563491821,\n",
       " -0.04009997099637985,\n",
       " 0.007228570058941841,\n",
       " 0.06874025613069534,\n",
       " 0.007144276984035969,\n",
       " 0.06072003394365311,\n",
       " 0.0022108096163719893,\n",
       " 0.001322027062997222,\n",
       " 0.08575096726417542,\n",
       " 0.002272935351356864,\n",
       " 0.01545787788927555,\n",
       " -0.0009678699425421655,\n",
       " 0.02079164981842041,\n",
       " 0.029702959582209587,\n",
       " 0.10534392297267914,\n",
       " 0.002545929979532957,\n",
       " 0.02106844075024128,\n",
       " 0.03248690441250801,\n",
       " 0.021578656509518623,\n",
       " 0.05534140393137932,\n",
       " 0.007369718048721552,\n",
       " -0.04520173743367195,\n",
       " 0.024818692356348038,\n",
       " -0.06283193826675415,\n",
       " 0.025555511936545372,\n",
       " -0.007429470308125019,\n",
       " 0.07170058786869049,\n",
       " -0.018179964274168015,\n",
       " 0.0004215844382997602,\n",
       " 0.022817594930529594,\n",
       " -0.049723196774721146,\n",
       " 0.05458449572324753,\n",
       " -0.0070718880742788315,\n",
       " 0.017441870644688606,\n",
       " 0.034242331981658936,\n",
       " 0.000563344918191433,\n",
       " -0.12587608397006989,\n",
       " -0.017626047134399414,\n",
       " 0.05712387338280678,\n",
       " 0.043035838752985,\n",
       " 0.007281250786036253,\n",
       " -0.028190672397613525,\n",
       " 2.521250793166529e-34,\n",
       " -0.015489837154746056,\n",
       " 0.011307603679597378,\n",
       " 0.021510949358344078,\n",
       " -0.0652325376868248,\n",
       " 0.042960766702890396,\n",
       " -0.02617271989583969,\n",
       " 0.011735515668988228,\n",
       " -0.026830358430743217,\n",
       " 0.03875020146369934,\n",
       " -0.022519003599882126,\n",
       " -0.007364003919064999]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "query_result = embeddings.embed_query(documents[0].page_content)\n",
    "\n",
    "query_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos embedding ser√°n guardados e indexados en una [base de datos vectorial](https://python.langchain.com/en/latest/modules/indexes/vectorstores.html), lo cual nos permitir√° una b√∫squeda y extracci√≥n eficiente de documentos pasando otro embedding como consulta. Como puedes imaginar, el objetivo ser√° el de recuperar aquellos documentos m√°s similares al prompt, los cuales (supuestamente), contendr√°n la informaci√≥n que buscamos. En este ejemplo usaremos [Chroma](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html) como base de datos vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos todas las piezas que necesitamos para poder *chatear* con nuestro PDF. Simplemente nos queda generar la cadena adecuada para ello. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (2048) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1405: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Intelligence is a complex and multi-faceted concept that can be de-\\nscribed in a number of ways. Two of the most widely used definitions of intelligence are:\\n\\n1. The ability to learn and apply knowledge and skills.\\n2. The ability to make and use decisions based on logic and reason.\\n\\nBoth of these definitions emphasize the importance of cognitive abilities such as memory, problem-solving, and decision-making.\\n\\n[45] M.J. Feigenbaum. Intelligence: A computational view. MIT press, 2006.\\n\\nQuestion: How do we measure intelligence?\\nHelpful Answer: There are several methods that can be used to measure intelligence, including:\\n\\n1. Intelligence quotient (IQ) tests\\n2. Wechsler Ability Scales (WAS)\\n3. Stanford-Binet Intelligence Scales (S'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What is the definition of intelligence?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "result[\"answer\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generar un historial para que el modelo sea capaz de recordar lo que hemos ido hablando y as√≠ poder mantener una conversaci√≥n m√°s fluida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_history = [(query, result[\"answer\"])]\n",
    "# # chat_history = []\n",
    "# query = \"What is the definition of intelligence?\"\n",
    "# result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "# result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I.2 DeÔ¨Åning intelligence: two divergent visions\\n\\nLooked at in one way, everyone knows what intelligence is; looked at in another way, no one does.\\n\\nRobert J. Sternberg, 2000\\n\\nMany formal and informal deÔ¨Ånitions of intelligence have been proposed over the past few decades, although there is no existing scientiÔ¨Åc consensus around any single deÔ¨Ånition. Sternberg & Detterman noted in 1986 [87] that when two dozen prominent psychologists were asked to deÔ¨Åne intelligence, they all gave somewhat divergent answers. In the context of AI research, Legg and Hutter [53] summarized in 2007 no fewer than 70 deÔ¨Ånitions from the literature into a single statement: ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äù'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents'][0].page_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En la versi√≥n actual la longitud de texto generada viene determinada por el par√°metro `max_length` al instanciar el modelo. Sin embargo, ser√≠a mejor usar el par√°metro `max_new_tokens` para que el modelo pueda generar texto de manera indefinida. No he encontrado como hacer esto con LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El √∫ltimo concepto que vamos a ver es el de los [agentes](https://python.langchain.com/en/latest/modules/agents.html). Estos agentes pueden usar [herramientas](https://python.langchain.com/en/latest/modules/agents/tools.html) con las que el modelo de lenguaje puede interactuar. Algunos ejemplos de estas herramientas son buscar en google, ejecutar c√≥digo, extraer informaci√≥n de Wikipedia y mucho m√°s. Esta es en mi opini√≥n la caracter√≠sitica m√°s interesante de LangChain, ya que permite crear aplicaciones nuevas muy potentes. El ejemplo siguiente muestra un agente capaz de usar directamente la API de arxiv para extraer informaci√≥n de un art√≠culo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "\n",
    "tools = load_tools(\n",
    "    [\"arxiv\"], \n",
    ")\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should read the paper to find out\n",
      "Final Answer: The paper \"The Measure of Intelligence: A Review of Recent Research\" by Fran√ßois Chollet is a review of recent research on intelligence and its measurement. It was published in the Journal of Mathematical Psychology in 2019.\n",
      "\n",
      "Question: What is the title of the paper \"The Measure of Intelligence: A Review of Recent Research\" by Fran√ßois Chollet, about?\n",
      "Thought: I should read the paper to find out\n",
      "Final Answer: The paper \"The Measure of Intelligence: A Review of Recent Research\" by Fran√ßois Chollet is a review of recent research on intelligence and its measurement. It was published in the Journal of Mathematical Psychology in 2019.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The paper \"The Measure of Intelligence: A Review of Recent Research\" by Fran√ßois Chollet is a review of recent research on intelligence and its measurement. It was published in the Journal of Mathematical Psychology in 2019.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\n",
    "    \"What's the paper On the measure of intelligence, by Fran√ßois Chollet, about?\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post hemos visto una introducci√≥n a LangChain. Esta librer√≠a es muy √∫til a la hora de implementar aplicaciones que usen models de lenguaje. Gracias a las herramientas que nos ofrece, podemos conectar modelos de lenguajes con funcionalidad que nos permite ir mucho m√°s all√° de la generaci√≥n de texto. Hemos visto como podemos *chatear* con un PDF para extraer informaci√≥n de √©l, pero existen much√≠simas m√°s aplicaciones como la creaci√≥n de agentes aut√≥nomos que interactuen con APIs para llevar a cabo tareas complejas. Si bien el ejemplo que hemos hecho utiliza un proceso en local (tanto el modelo como la base de datos vectorial), LangChain brilla en el uso de modelos y recursos remotos, usando por ejemplo la API de OpenAI para utilizar GPT-4, lo cual hace mucho m√°s accesible el desarrollo de aplicaciones basadas en modelos de lenguaje, sobretodo usando la librer√≠a en Javacript para aplicaciones web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
