{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/117_langchain/117_langchain.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain ðŸ¦œðŸ”—"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el despegue de los modelos de lenguaje que estamos viviendo en este momento cientos de nuevas herramientas y aplicaciones estÃ¡n apareciendo para aprovechar el poder de estas redes neuronales. Una de ellas parece destacar por encima del resto, y Ã©sta es [LangChain](https://docs.langchain.com/docs/). En este post vamos a ver quÃ© es y cÃ³mo podemos usarla."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â¿QuÃ© es LangChain?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SegÃºn su [documentaciÃ³n](https://docs.langchain.com/docs/), Langchain es un entorno de desarrollo de aplicaciones basadas en modelos de lenguajes. Las herramientas proporcionadas por LangChain permiten, por un lado, conectar modelos de lenguaje con otras fuentes de datos (como por ejemplo tus porpios documentos, bases de datos o emails) y, por otro lado, permitir a estos modelos interactuar con su entorno (por ejemplo, enviando emails o llamando a APIs web). Langchain ofrece librerÃ­as en Python y Javascript para facilitar el desarrollo de estas aplicaciones, en este post nos centraremos en la librerÃ­a de Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un ejemplo prÃ¡ctico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos viendo un ejemplo prÃ¡ctico de cÃ³mo usar LangChain para proporcionar informaciÃ³n sobre un documento, y luego entraremos en detalle de los diferentes componentes y cÃ³mo funcionan.\n",
    "\n",
    "> Vamos a usar como documento el artÃ­culo [On the Measure of Intelligence](https://arxiv.org/pdf/1911.01547.pdf), de FranÃ§ois Chollet (2019)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que necesitamos es instalar la librerÃ­a de LangChain:\n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.160'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero cargamos el documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1911.01547.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "pdfs = glob('*.pdf')\n",
    "pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "detectron2 is not installed. Cannot use the hi_res partitioning strategy. Falling back to partitioning with the fast strategy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='9 1 0 2\\n\\nv o N 5 2\\n\\n] I\\n\\nA . s c [\\n\\n2 v 7 4 5 1 0 . 1 1 9 1 : v i X r a\\n\\nOn the Measure of Intelligence\\n\\nFrancÂ¸ois Chollet âˆ— Google, Inc. fchollet@google.com\\n\\nNovember 5, 2019\\n\\nAbstract\\n\\nTo make deliberate progress towards more intelligent and more human-like artiï¬cial systems, we need to be following an appropriate feedback signal: we need to be able to deï¬ne and evaluate intelligence in a way that enables comparisons between two systems, as well as comparisons with humans. Over the past hundred years, there has been an abun- dance of attempts to deï¬ne and measure intelligence, across both the ï¬elds of psychology and AI. We summarize and critically assess these deï¬nitions and evaluation approaches, while making apparent the two historical conceptions of intelligence that have implicitly guided them. We note that in practice, the contemporary AI community still gravitates to- wards benchmarking intelligence by comparing the skill exhibited by AIs and humans at speciï¬c tasks, such as board games and video games. We argue that solely measuring skill at any given task falls short of measuring intelligence, because skill is heavily modulated by prior knowledge and experience: unlimited priors or unlimited training data allow ex- perimenters to â€œbuyâ€ arbitrary levels of skills for a system, in a way that masks the systemâ€™s own generalization power. We then articulate a new formal deï¬nition of intelligence based on Algorithmic Information Theory, describing intelligence as skill-acquisition efï¬ciency and highlighting the concepts of scope, generalization difï¬culty, priors, and experience, as critical pieces to be accounted for in characterizing intelligent systems. Using this deï¬- nition, we propose a set of guidelines for what a general AI benchmark should look like. Finally, we present a new benchmark closely following these guidelines, the Abstraction and Reasoning Corpus (ARC), built upon an explicit set of priors designed to be as close as possible to innate human priors. We argue that ARC can be used to measure a human-like form of general ï¬‚uid intelligence and that it enables fair general intelligence comparisons between AI systems and humans.\\n\\nâˆ—I thank JosÂ´e HernÂ´andez-Orallo, Julian Togelius, Christian Szegedy, and Martin Wicke for their valuable com-\\n\\nments on the draft of this document.\\n\\n1\\n\\nContents\\n\\nI Context and history\\n\\nI.2.1 I.2.2\\n\\nI.1 Need for an actionable deï¬nition and measure of intelligence . . . . . . . . . . . . . . . . . . . . . . . . . I.2 Deï¬ning intelligence: two divergent visions . . . . . . . . . . . . Intelligence as a collection of task-speciï¬c skills Intelligence as a general learning ability . . . . . . . . . . . . . . . . . I.3 AI evaluation: from measuring skills to measuring broad abilities . . . . . . Skill-based, narrow AI evaluation . . . . . . . . . . . . . . . . . . . . The spectrum of generalization: robustness, ï¬‚exibility, generality . . .\\n\\nI.3.1 I.3.2 I.3.3 Measuring broad abilities and general intelligence: the psychometrics\\n\\n3 3 4 5 6 7 7 9\\n\\n.\\n\\n.\\n\\n. . . . . .\\n\\n. . . . . . . . . . . . . . . . . . . . . . . 13 perspective . . . . . . . . . . . . . . . 14 Integrating AI evaluation and psychometrics Current trends in broad AI evaluation . . . . . . . . . . . . . . . . . . 16\\n\\nI.3.4 I.3.5\\n\\nII A new perspective\\n\\nII.1 Critical assessment .\\n\\n.\\n\\n18 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n\\nII.1.1 Measuring the right thing: evaluating skill alone does not move us\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\nII.1.2 II.1.3\\n\\nforward . The meaning of generality: grounding the g factor Separating the innate from the acquired: insights from developmental psychology .\\n\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 . . . . . . . . . . . 20\\n\\n. . . . . . . . . . . . . . . . . . . . . . . 24 II.2 Deï¬ning intelligence: a formal synthesis . . . . . . . . . . . . . . . . . . . 27 Intelligence as skill-acquisition efï¬ciency . . . . . . . . . . . . . . . . 27', metadata={'source': '/tmp/tmpgtp6ichu'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import OnlinePDFLoader\n",
    "\n",
    "loader = OnlinePDFLoader(\"https://arxiv.org/pdf/1911.01547.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mindexes\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorstoreIndexCreator\n\u001b[0;32m----> 2\u001b[0m index \u001b[39m=\u001b[39m VectorstoreIndexCreator()\u001b[39m.\u001b[39mfrom_loaders([loader])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:339\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:1066\u001b[0m, in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/fields.py:439\u001b[0m, in \u001b[0;36mpydantic.fields.ModelField.get_default\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device has 2 GPUs available. Provide device={deviceId} to `from_model_id` to use availableGPUs for execution. deviceId is -1 (default) for CPU and can be a positive integer associated with CUDA device id.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=\"bigscience/bloom-1b7\", task=\"text-generation\", model_kwargs={\"temperature\":0, \"max_length\":64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (64) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First, we need to understand what is an electroencephalogram. An electroencephalogram is a recording of brain activity. It is a recording of brain activity that is made by placing electrodes on the scalp. The electrodes are placed\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,  LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Componentes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data loading](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
