{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4453ecd4",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/072_pytorch_docker_/072_pytorch_docker_.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a8999",
   "metadata": {},
   "source": [
    "# Pytorch NGC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e83ae4",
   "metadata": {},
   "source": [
    "En los posts anteriores hemos visto muchos trucos para optimizar nuestro cÃ³digo en Pytorch, sin embargo no nos hemos preocupado por la instalaciÃ³n del mismo. En este post vamos a aprender a usar una versiÃ³n de `Pytorch` optimizada que en alguna ocasiÃ³n nos darÃ¡ un pequeÃ±o extra de performance. Para ello vamos a usar `Docker`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db69ad4",
   "metadata": {},
   "source": [
    "## Â¿QuÃ© es `Docker`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3cd217",
   "metadata": {},
   "source": [
    "[`Docker`](https://www.docker.com/) es una tecnologÃ­a que nos permite crear entornos de software paquetizados y aisaldos del resto de componenetes en un sistema operativo. Similar en espÃ­ritu a una mÃ¡quina virtual, o a los entornos virtuales de `Python`, con `Docker` podremos crear imÃ¡genes (que contendrÃ¡n nuestro cÃ³digo y sus dependencias) que serÃ¡n ejectuadas en contenedores (el entorno aislado). De esta manera estremos seguros que nuestro cÃ³digo funcionarÃ¡ en cualquier plataforma siempre y cuando `Docker` estÃ© instalado.\n",
    "\n",
    "![](https://thingsolver.com/wp-content/uploads/pasted-image-0-768x452-1.png)\n",
    "\n",
    "No es el objetivo de este post explicar en detalle cÃ³mo trabajar con `Docker`, para ello existen multitud de tutoriales en internet. Pero sÃ­ que vamos a ver como podemos aplicar esta tecnlogÃ­a a la hora de trabajar con `Pytorch`.\n",
    "\n",
    "> âš ï¸ Si bien puedes instalar `Docker` en cualquier sistema operativo, lo que vamos a ver en este post sÃ³lo funciona en Linux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fcdc2",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef2114",
   "metadata": {},
   "source": [
    "Para poder trabajar con `Pytorch` y `Docker` necesitamos instalar las siguientes dependencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f092f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T13:43:42.114525Z",
     "start_time": "2021-06-29T13:43:42.108116Z"
    }
   },
   "source": [
    "- [`Docker`](https://docs.docker.com/engine/install/ubuntu/)\n",
    "- [`nvidia-docker`](https://github.com/NVIDIA/nvidia-docker) (para que `Docker` puedas usar nuestra `GPU`)\n",
    "- Opcionalmente, instala [`docker-compose`](https://docs.docker.com/compose/install/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bb85f",
   "metadata": {},
   "source": [
    "## Ejecutando `Jupyter Notebooks` en `Docker`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77151cc",
   "metadata": {},
   "source": [
    "Lo primero que vamos a ver es como ejecutar una imÃ¡gen de `Docker` con `Python`. Para ello, una vez hayas instalado `Docker`, ejecuta el siguiente comando en la terminal:\n",
    "\n",
    "```\n",
    "docker run -it python:3.9-slim python\n",
    "```\n",
    "\n",
    "Esto descargarÃ¡ la imÃ¡gen `python:3.9-slim` de [`dockerhub`](https://hub.docker.com/) si no la encuentra en el sistema y luego ejecutarÃ¡ el comando `python`. Al haber indicado a `Docker` que lo ejecute en modo interactivo (-it) se abrirÃ¡ un terminal de `Python` dentro del contenedor. Como puedes ver, si necesitas una versiÃ³n de `Python` diferente simplemente tendrÃ¡s que indicarle el `tag` apropiado.\n",
    "\n",
    "Para abrir un `notebook` puedes usar el comando siguiente:\n",
    "\n",
    "```\n",
    "docker run python:3.9-slim jupyter notebook\n",
    "```\n",
    "\n",
    "sin embargo esto darÃ¡ un error, y es que la imÃ¡gen usada no tiene `jupyter notebook` instalado. Tenemos dos opciones, usar una imÃ¡gen diferente que sÃ­ lo tenga o bien crearnos nuestra propia imÃ¡gen. Para ello, crea un archivo llamado `Dockerfile` con el siguiente contenido:\n",
    "\n",
    "\n",
    "```\n",
    "FROM python:3.9-slim\n",
    "\n",
    "RUN pip install jupyter\n",
    "\n",
    "WORKDIR /workspace\n",
    "``` \n",
    "\n",
    "Ahora puedes crear tu propia imÃ¡gen con el comando\n",
    "\n",
    "```\n",
    "docker build -t jupyter .\n",
    "```\n",
    "\n",
    "Y ejectuarla de la siguiente manera\n",
    "\n",
    "```\n",
    "docker run jupyter jupyter notebook --allow-root\n",
    "```\n",
    "\n",
    "Sin embargo, esto seguirÃ¡ sin funcionar. El motivo es que nuestra imÃ¡gen estÃ¡ siendo ejectuada en un entorno aisaldo, en el que no existe un navegador ni tampoco forma de poder conectarnos. Para solventar este problema ejecutaremos el comando\n",
    "\n",
    "```\n",
    "docker run -p 8888:8888 jupyter  jupyter notebook --allow-root --no-browser --ip=0.0.0.0\n",
    "```\n",
    "\n",
    "Ahora ya podrÃ¡s usar tus notebooks !!! Sin embargo, si creas un nuevo notebook y paras el contenedor, al volver a abrirlo habrÃ¡ desaparecido. Esto es debido a que, como ya hemos comentado, nuestro cÃ³digo se ejecuta en un entorno aislado por lo que no tendremos persistencia en nuestros archivos. Para solventarlo, usarmos el conceptro de `volumes` (carpetas compartidas entre nuestro ordenador y `Docker`).\n",
    "\n",
    "```\n",
    "docker run -p 8888:8888 -v ${PWD}/ipynbs:/workspace/ipynbs jupyter  jupyter notebook --allow-root --no-browser --ip=0.0.0.0\n",
    "```\n",
    "\n",
    "Con esto tenemos todo lo necesario para trabajar con notebooks en `Docker`. Te recomiendo como Ãºltimo paso utilizas `docker-compose` ya que tener que ejecutar un comando tan largo en la consola puede convertirse en algo tedioso. `Docker-compose` es una herramienta que nos permite ejecutar nuestros contenedores usando archivos de configuraciÃ³n (entre muchas otras cosas que no veremos aquÃ­). Para ello, crea un archivo llamado `docker-compose.yml` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "version: \"3.0\"\n",
    "\n",
    "services:\n",
    "  jupyter:\n",
    "    container_name: jupyter\n",
    "    image: jupyter\n",
    "    build: .\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    volumes:\n",
    "      - ./ipynbs:/workspace/ipynbs\n",
    "    command: jupyter notebook --allow-root --ip=0.0.0.0 --no-browser \n",
    "```\n",
    "\n",
    "Puedes crear tus imÃ¡genes con el comando `docker-compose build`, ejecutar el contenedor con `docker-compose up` y pararlo con `docker-compose down`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293d4ed",
   "metadata": {},
   "source": [
    "## `Pytorch` en `Docker`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa46eeb",
   "metadata": {},
   "source": [
    "Vamos ahora a ver cÃ³mo podemos trabajar con `Pytorch` en `Docker`. Si bien podemos hacer como antes e instalar `Pytorch` en nuestra imÃ¡gen, ahora haremos lo contrario y usaremos una imÃ¡gen ya hecha. El motivo es que podemos encontrar imÃ¡genes en internet con instalaciones optimizadas que nos pueden dar un extra de performance en ciertos casos gracias al acceso a nuevas caracterÃ­sticas o funcionalidad no implementadas en la distribuciÃ³n oficial que podemos instalar con `conda`. Un repositorio muy recomendado en [`ngc`](https://ngc.nvidia.com/catalog/containers?orderBy=scoreDESC&pageNumber=0&query=pytorch&quickFilter=&filters=), en el que podemos encontrar instalaciones de `Pytorch` opimizadas por los propios ingenieros de `NVIDIA`. Puedes ejecutar un notebook con esta imÃ¡gen con el siguiente `docker-compose`.\n",
    "\n",
    "```\n",
    "version: \"2.3\"\n",
    "\n",
    "services:\n",
    "  pytorch-ngc:\n",
    "    runtime: nvidia\n",
    "    container_name: pytorch-ngc\n",
    "    image: nvcr.io/nvidia/pytorch:21.06-py3\n",
    "    ipc: host\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    volumes:\n",
    "      - ./ipynbs:/workspace\n",
    "      - ./data:/workspace/data\n",
    "    environment:\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "    command: jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123\n",
    "```\n",
    "\n",
    "Aunque es muy probable que en algÃºn momento quieras customizar esta imÃ¡gen para incluir alguna librerÃ­a extra, como por ejemplo `Pytorch Lightning` (si bien existe una imÃ¡gen con esta librerÃ­a instalada, vamos a ver un ejemplo de cÃ³mo puedes aÃ±adir tus propias dependencias). Para ello, ya sabes que tienes que crear un `Dockerfile`.\n",
    "\n",
    "```\n",
    "FROM nvcr.io/nvidia/pytorch:21.06-py3\n",
    "\n",
    "RUN pip install --upgrade pip && pip install \\\n",
    "    pytorch-lightning \\\n",
    "    timm \\\n",
    "    pytorch-segmentation-models\n",
    "\n",
    "WORKDIR /workspace\n",
    "```\n",
    "\n",
    "Y luegos puedes usar el siguiente `docker-compose`.\n",
    "\n",
    "```\n",
    "version: \"2.3\"\n",
    "\n",
    "services:\n",
    "  pytorch-ngc:\n",
    "    runtime: nvidia\n",
    "    container_name: pytorch-ngc\n",
    "    image: pytorch-ngc\n",
    "    build: .\n",
    "    ipc: host\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    volumes:\n",
    "      - ./ipynbs:/workspace\n",
    "      - ./data:/workspace/data\n",
    "    environment:\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "    command: jupyter notebook --allow-root --ip=0.0.0.0 --no-browser --NotebookApp.token=abc123\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e648f75",
   "metadata": {},
   "source": [
    "Una vez hayas jugado un poco con todo lo visto hasta ahora, puedes intentar abrir este mismo notebook con `Docker` y ejectuar el siguiente cÃ³digo para entrenar una red neuronal. Para ello necesitarÃ¡s descargar el dataset [EuroSAT](https://github.com/phelber/eurosat) y colocarlo en la carpeta `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0ef4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937b94d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fdebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images and labels ...\n",
      "Number of images: 27000\n",
      "Generating train / val splits ...\n",
      "Training samples:  21600\n",
      "Validation samples:  5400\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def setup(path='./data', test_size=0.2, random_state=42):\n",
    "\n",
    "    classes = sorted(os.listdir(path))\n",
    "\n",
    "    print(\"Generating images and labels ...\")\n",
    "    images, encoded = [], []\n",
    "    for ix, label in enumerate(classes):\n",
    "        _images = os.listdir(f'{path}/{label}')\n",
    "        images += [f'{path}/{label}/{img}' for img in _images]\n",
    "        encoded += [ix]*len(_images)\n",
    "    print(f'Number of images: {len(images)}')\n",
    "\n",
    "     # train / val split\n",
    "    print(\"Generating train / val splits ...\")\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "        images,\n",
    "        encoded,\n",
    "        stratify=encoded,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(\"Training samples: \", len(train_labels))\n",
    "    print(\"Validation samples: \", len(val_labels))\n",
    "    \n",
    "    return classes, train_images, train_labels, val_images, val_labels\n",
    "\n",
    "classes, train_images, train_labels, val_images, val_labels = setup('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd1cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from skimage import io \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        img = io.imread(self.images[ix])[...,(3,2,1)]\n",
    "        img = torch.tensor(img / 4000, dtype=torch.float).clip(0,1).permute(2,0,1)  \n",
    "        label = torch.tensor(self.labels[ix], dtype=torch.long)        \n",
    "        return img, label\n",
    "    \n",
    "ds = {\n",
    "    'train': Dataset(train_images, train_labels),\n",
    "    'val': Dataset(val_images, val_labels)\n",
    "}\n",
    "\n",
    "batch_size = 1024\n",
    "dl = {\n",
    "    'train': torch.utils.data.DataLoader(ds['train'], batch_size=batch_size, shuffle=True, num_workers=20, pin_memory=True),\n",
    "    'val': torch.utils.data.DataLoader(ds['val'], batch_size=batch_size, shuffle=False, num_workers=20, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a96191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_outputs=10, use_amp=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('tf_efficientnet_b5', pretrained=True, num_classes=n_outputs)\n",
    "        self.use_amp = use_amp\n",
    "\n",
    "    def forward(self, x, log=False):\n",
    "        if log:\n",
    "            print(x.shape)\n",
    "        with torch.cuda.amp.autocast(enabled=self.use_amp):\n",
    "            return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4433ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def step(model, batch, device):\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_hat = model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    acc = (torch.argmax(y_hat, axis=1) == y).sum().item() / y.size(0)\n",
    "    return loss, acc\n",
    "\n",
    "def train_amp(model, dl, optimizer, epochs=10, device=\"cpu\", use_amp = True, prof=None, end=0):\n",
    "    model.to(device)\n",
    "    hist = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    for e in range(1, epochs+1):\n",
    "        # train\n",
    "        model.train()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['train'])\n",
    "        stop=False\n",
    "        for batch_idx, batch in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # AMP\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                loss, acc = step(model, batch, device)\n",
    "            scaler.scale(loss).backward()\n",
    "            # gradient clipping \n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            l.append(loss.item())\n",
    "            a.append(acc)\n",
    "            bar.set_description(f\"training... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "            # profiling\n",
    "            if prof:\n",
    "                if batch_idx >= end:\n",
    "                    stop = True\n",
    "                    break\n",
    "                prof.step()  \n",
    "        hist['loss'].append(np.mean(l))\n",
    "        hist['acc'].append(np.mean(a))\n",
    "        if stop:\n",
    "            break\n",
    "        # eval\n",
    "        model.eval()\n",
    "        l, a = [], []\n",
    "        bar = tqdm(dl['val'])\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                loss, acc = step(model, batch, device)\n",
    "                l.append(loss.item())\n",
    "                a.append(acc)\n",
    "                bar.set_description(f\"evluating... loss {np.mean(l):.4f} acc {np.mean(a):.4f}\")\n",
    "        hist['val_loss'].append(np.mean(l))\n",
    "        hist['val_acc'].append(np.mean(a))\n",
    "        # log\n",
    "        log = f'Epoch {e}/{epochs}'\n",
    "        for k, v in hist.items():\n",
    "            log += f' {k} {v[-1]:.4f}'\n",
    "        print(log)\n",
    "        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d11e862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 1.4168 acc 0.7123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:11<00:00,  1.88it/s]\n",
      "evluating... loss 7.0801 acc 0.3112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.25it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 loss 1.4168 acc 0.7123 val_loss 7.0801 val_acc 0.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.1586 acc 0.9484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.05it/s]\n",
      "evluating... loss 0.4077 acc 0.8919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.26it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 loss 0.1586 acc 0.9484 val_loss 0.4077 val_acc 0.8919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training... loss 0.0436 acc 0.9868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:10<00:00,  2.02it/s]\n",
      "evluating... loss 0.2022 acc 0.9483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 loss 0.0436 acc 0.9868 val_loss 0.2022 val_acc 0.9483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "hist = train_amp(model, dl, optimizer, epochs=3, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc89a9d5",
   "metadata": {},
   "source": [
    "## Scripts en Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1b13f",
   "metadata": {},
   "source": [
    "Si bien trabajar con notebooks es muy conveniente en la mayorÃ­a de ocasiones, es posible que alternativamente quieras ejectuar un `script` dentro del contenedor de `Docker`. Puedes usar un `volume` para cargar tu cÃ³digo en el contenedor (ideal durante el desarrollo) o directamente copiar el `script` en la imÃ¡gen (ideal si quieres compartir tu cÃ³digo o ejectuarlo en mÃ¡quinas remotas).\n",
    "\n",
    "```\n",
    "FROM nvcr.io/nvidia/pytorch:21.06-py3\n",
    "\n",
    "RUN pip install --upgrade pip && pip install \\\n",
    "    pytorch-lightning \\\n",
    "    timm \\\n",
    "    segmentation-models-pytorch\n",
    "\n",
    "COPY ./main.py /workspace/main.py\n",
    "\n",
    "WORKDIR /workspace\n",
    "```\n",
    "\n",
    "Los datos los seguirÃ¡s teniendo que cargar en un `volume` ya que meterlos en la imÃ¡gen serÃ­a algo feo ðŸ˜›, igualmente asegÃºrate de usar otro `volume` en el que guardar tus resultados.\n",
    "\n",
    "```\n",
    "version: \"2.3\"\n",
    "\n",
    "services:\n",
    "  pytorch-script:\n",
    "    runtime: nvidia\n",
    "    container_name: pytorch-script\n",
    "    image: pytorch-script\n",
    "    build: .\n",
    "    ipc: host\n",
    "    volumes:\n",
    "      - ./data:/workspace/data\n",
    "    environment:\n",
    "      - NVIDIA_VISIBLE_DEVICES=all\n",
    "    command: python main.py\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e55187",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ca191",
   "metadata": {},
   "source": [
    "`Docker` es una herramienta muy Ãºtil a la hora de gestionar nuestro cÃ³digo y sus dependencias. En este post hemos visto un ejemplo de cÃ³mo usarlo junto a `Pytorch`, pero lo puedes usar para muchas otras aplicaciones (webs, bases de datos, ...). Hemos aprendido a ejectuar notebooks dentro de contenedores (para lo cual necesitamos configurar los puertos y volÃºmenes adecuados), usar versiones optimizadas de `Pytorch` gracias al `NGC` de `NVIDIA` y crear nuestras propias imÃ¡genes con nuestro cÃ³digo y dependencias."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd3c0ff7553675f8399160a12fbc0c6054e9524c8e841ec60a211865d03cacc2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
