{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/091_dlops_deployment/091_dlops_deployment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLOps - Despliegue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post vamos a aprender como desplegar nuestros modelos en producci칩n. Para ello usaremos [FastAPI](https://fastapi.tiangolo.com/), un *framework* de Python para el desarrollo de APIs, [Docker](https://www.docker.com/) para paquetizar la API y [Heroku](https://www.heroku.com/) para desplegar la API en producci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien existen diferente frameworks para crear APIs en Python, como Flask por ejemplo, aqu칤 vamos a usar `FastAPI` ya que nos ofrece un mont칩n de funcionalidad que usaremos a lo largo de esta serie de posts. Si no conoces este proyecto, te recomiendo que navegues por su [documentaci칩n](https://fastapi.tiangolo.com/tutorial/).\n",
    "\n",
    "> Pudes instalar FastAPI con el comando `pip install fastapi[all]`.\n",
    "\n",
    "Una vez instalado, crea un script llamado `app.py` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "```\n",
    "\n",
    "Ahora, puedes arrancar tu API en local con el comando `uvicorn app:app --reload`. Si todo va bien, deber칤as ver un mensaje similar a\n",
    "\n",
    "![](./pics/flask1.png)\n",
    "\n",
    "Si ahora abres tu navegador y escribes `http://localhost:8000/`, deber치s ver el mensaje devuelto por la API.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"message\": \"Hello World\"\n",
    "}\n",
    "```\n",
    "\n",
    "Sencillo, 쯨erdad? Ahora simplemente tenemos que hacer que esta API (que como puedes ver no es m치s que un script de Python) carge nuestro modelo, reciba entradas (en nuestro caso im치genes) y devuelva las predicciones. Esto lo conseguiremos con el siguiente c칩digo:\n",
    "\n",
    "```\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from PIL import Image\n",
    "import onnxruntime as ort \n",
    "import numpy as np\n",
    "import io\n",
    "import math\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "ort_session = ort.InferenceSession('models/binary_classifier_3.onnx')\n",
    "TRHESHOLD = 0.5\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Hello World\"}\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    request_object_content = await file.read()\n",
    "    img = Image.open(io.BytesIO(request_object_content))\n",
    "    input = np.expand_dims(np.array(img, dtype=np.uint8), axis=0)\n",
    "    ort_inputs = {\n",
    "        \"input\": input\n",
    "    }\n",
    "    ort_output = ort_session.run(['output'], ort_inputs)[0]\n",
    "    output = sigmoid(ort_output)\n",
    "    return {\n",
    "        \"proba\": output,\n",
    "        \"label\": \"3\" if output > TRHESHOLD else \"no 3\"\n",
    "    }\n",
    "```\n",
    "\n",
    "Una de las ventajas que FastAPI ofrece es la de generaci칩n autom치tica de documentaci칩n interactiva. Si visitas `http://localhost:8000/docs`, podr치s probar tu nuevo *endpoint* al cual enviarle im치genes y recibir las predicciones del modelo. Si칠ntete libre de personalizar tu API a tu gusto 游때."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez implementada la l칩gica de nuestra API es momento de desplegarla en la nube para que todo el mundo tenga acceso. Sin embargo, para facilitar este proceso, primero crearemos una im치gen de `Docker` que contendr치 el c칩digo de nuestra `API` y todas sus dependencias. Esto nos evitar치 dolores de cabeza a la hora de crear el entorno de producci칩n adecuado (versi칩n de sistema operativo, versi칩n de dependencias, ...). Simplemente, si nuestro servidor tiene `Docker` instalado, ser치 capaz de ejecutar nuestra `API`. \n",
    "\n",
    "> Puedes instalar `Docker` siguiendo las [instrucciones](https://docs.docker.com/engine/install/).\n",
    "\n",
    "Crea un archivo llamado `Dockerfile` con el siguiente contenido:\n",
    "\n",
    "```\n",
    "FROM continuumio/miniconda3\n",
    "\n",
    "RUN conda install -y -c conda-forge \\ \n",
    "    pillow \\\n",
    "    onnxruntime \\\n",
    "    fastapi \\ \n",
    "    uvicorn \\\n",
    "    python-multipart \n",
    "\n",
    "COPY ./models /models\n",
    "COPY ./app.py /app.py\n",
    "\n",
    "CMD uvicorn app:app --host=0.0.0.0 --port=$PORT\n",
    "```\n",
    "\n",
    "Y, para crear la imagen de `Docker`, ejecuta el comando `docker build -t dlops .`, donde `dlops` es el nombre que le quieras dar a tu imagen. Ahora podr치s ejectuar la im치gen de `Docker` con el comando `docker run -p 8000:8000 -e PORT=8000 dlops` para arrancar la API.\n",
    "\n",
    "> Durante el desarrollo con `Docker` no es recomendable copiar directamente tu c칩digo fuente en el paso de `build`, ya que si haces cambios estos no se reflejar치n hasta que hagas un nuevo `build`. Para ello te dejo como ejemplo el archivo `Dockerfile.dev` y `docker-compose-yml`, que \"montan\" el c칩digo como un volumen dentro de la imagen `Docker` y por lo tanto estos cambios si se ver치n reflejados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 칰ltimo paso es el de subir nuestra imagen de `Docker` a `Heroku` y ejectuarla para obtener ana `url` p칰blica con la que tener acceso a nuestra `API`. \n",
    "\n",
    "> Puedes instalar la `CLI` de Horeku siguiendo las [instrucciones](https://devcenter.heroku.com/articles/heroku-cli#install-the-heroku-cli).\n",
    "\n",
    "Lo primero que necesitaremos ser치 logearnos en Heroku usando la CLI.\n",
    "\n",
    "```\n",
    "heroku login\n",
    "```\n",
    "\n",
    "Una vez logeados deberemos generar las credenciales necesarias para guardar nuestra imagen de `Docker` en el registro de `Heroku`\n",
    "\n",
    "```\n",
    "heroku container:login\n",
    "```\n",
    "\n",
    "Con el comando `hrekou create` podemos crear una nueva aplicaci칩n, de la cual obtendremos una `url` p칰blica. Para desplegar nuestra apliaci칩n deberemos ejecutar el siguiente comando:\n",
    "\n",
    "```\n",
    "heroku container:push web -a <nombre>\n",
    "```\n",
    "\n",
    "donde `<nombre>` es el subdominio de la `url` generada en el paso anterior. La imagen de `Docker` se subir치 al registro y ya podemos desplegarla con el comando\n",
    "\n",
    "```\n",
    "heroku container:release web -a <nombre>\n",
    "```\n",
    "\n",
    "춰Voil! Nuestra API est치 desplegada y tenemos acceso a trav칠s de la `url` generada. Puedes probar a navegar a la documentaci칩n (recuerda el endpoint `/docs` que hemos visto antes) y probar tu modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post hemos visto como podemos crear una `API` en `Python` para servir nuestro modelo. Para ello hemos usado `FastAPI`, un *framewrok* con buen rendimiento y multitud de funcionalidad incluida. Hemos usado `Docker` para paquetizar nuestro modelo, c칩digo de la `API` y todas sus dependencias de manera que sea facilmente desplegable. Por 칰ltimo, hemos usado `Heroku` para subir nuestra `API` a la nube y obtener una `url` p칰blica. Con esta `url` cualquier persona o aplicaci칩n puede acceder a nuestro modelo, enviando im치genes y recibiendo las predicciones."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
