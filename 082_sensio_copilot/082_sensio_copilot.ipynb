{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/082_sensio_copilot/082_sensio_copilot.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensio CoPilot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post vamos a entrenar una red neuronal para generaci√≥n de c√≥digo similar al funcionamiento de [github Copilot](https://copilot.github.com/). Llevo usando Copilot unos meses y la verdad que puedo decir que es una herramienta incre√≠ble, que ha aumentado considerablemente mi productividad como programador. Hace unos d√≠as le√≠ [este](https://twitter.com/lvwerra/status/1467933794699259908?s=21) hilo en Twitter y cre√≠ que ser√≠a interesante intentar replicar un sistema como Copilot desde cero. As√≠ que sin m√°s dilaci√≥n, ¬°vamos a ello!\n",
    "\n",
    "Github Copilot utiliza el modelo conocido como [Codex](https://arxiv.org/abs/2107.03374), desarrollado por OpenAI. Este modelo est√° basado en la arquitectura GPT (de lo que hablaremos m√°s adelante) y *tuneado* con c√≥digo p√∫blico extra√≠do de Github. Esto significa que el modelo fue pre-entrenado de manera no supervisada con mucho texto y luego se hizo *fine tuning* con el c√≥digo extra√≠do de Github para la tarea de generaci√≥n de texto (nuevo c√≥digo autocompletado). En contraste, nosotros entrenaremos un modelo desde cero para la tarea de generaci√≥n de texto con un dataset preparado para ello a modo de demostraci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset usado por OpenAI para entrenar Codex fue extra√≠do de 54 millones de reposiotrios p√∫blicos de Github, conteniendo 179 GB de archivos Python de menos de 1 MB. Tras varias etapas de procesado, el dataset final ocup√≥ 159 GB. Como no tenemos acceso a este dataset, usaremos [CodeParrot](https://huggingface.co/datasets/lvwerra/codeparrot-clean), un dataset elaborado por [HuggingFace](https://huggingface.co/) para la tarea de generaci√≥n de c√≥digo.\n",
    "\n",
    "> Recuerda que OpenAI al final tiene que ganar dinero de alguna manera, y √©sta es cobrando por el uso de sus modelos a trav√©s de la API. Siendo el modelo p√∫blico, su √∫nica ventaja competitiva reside en los datos usados durante el entrenamiento. Esto es una tendencia clara en el mundo del Software 2.0, d√≥nde el valor real est√° en los datos y no en el c√≥digo (aunque como dir√≠a Andrej Karpathy en el Software 2.0 los datos SON el c√≥digo y el modelo no es m√°s que el binario resultante de la compilaci√≥n del mismo, lo que llamamos el proceso de entrenamiento).\n",
    "\n",
    "El dataset ocupa unos 50 GB, aproximadamente una tercera parte del dataset usado originalmente por OpenAI. ¬°Nada mal! Puedes descargarlo utilizando los siguientes comandos:\n",
    "\n",
    "```\n",
    "git clone https://huggingface.co/datasets/lvwerra/codeparrot-clean-train\n",
    "git clone https://huggingface.co/datasets/lvwerra/codeparrot-clean-valid\n",
    "```\n",
    "\n",
    "> Para poder descargarlos necesitar√°s instalar [Git LFS](https://git-lfs.github.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52,\n",
       " ['codeparrot-clean-train/file-000000000007.json.gz',\n",
       "  'codeparrot-clean-train/file-000000000053.json.gz',\n",
       "  'codeparrot-clean-train/file-000000000026.json.gz'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "path = Path('data/codeparrot-clean-train')\n",
    "\n",
    "files = glob(str(path) + '/*.json.gz')\n",
    "len(files), files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_name</th>\n",
       "      <th>path</th>\n",
       "      <th>copies</th>\n",
       "      <th>size</th>\n",
       "      <th>content</th>\n",
       "      <th>license</th>\n",
       "      <th>hash</th>\n",
       "      <th>line_mean</th>\n",
       "      <th>line_max</th>\n",
       "      <th>alpha_frac</th>\n",
       "      <th>autogenerated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jalavik/inspire-next</td>\n",
       "      <td>setup.py</td>\n",
       "      <td>1</td>\n",
       "      <td>4558</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n#\\n# This file is par...</td>\n",
       "      <td>gpl-2.0</td>\n",
       "      <td>-4849180608980663294</td>\n",
       "      <td>27.848101</td>\n",
       "      <td>77</td>\n",
       "      <td>0.615840</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dlzhangxg/cloud-ml-sdk</td>\n",
       "      <td>cloud_ml_samples/keras/mnist/trainer/task.py</td>\n",
       "      <td>1</td>\n",
       "      <td>2967</td>\n",
       "      <td># Copyright 2017 Xiaomi, Inc.\\n#\\n# Licensed u...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>-1822461891537938192</td>\n",
       "      <td>30.231579</td>\n",
       "      <td>74</td>\n",
       "      <td>0.649815</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openstack/heat</td>\n",
       "      <td>heat/engine/support.py</td>\n",
       "      <td>1</td>\n",
       "      <td>2683</td>\n",
       "      <td>#\\n#    Licensed under the Apache License, Ver...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>-1815098437948811103</td>\n",
       "      <td>36.788732</td>\n",
       "      <td>78</td>\n",
       "      <td>0.622438</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imapp-pl/golem</td>\n",
       "      <td>tests/golem/network/test_golem_protocol.py</td>\n",
       "      <td>1</td>\n",
       "      <td>1444</td>\n",
       "      <td>import unittest\\nfrom devp2p.service import Wi...</td>\n",
       "      <td>gpl-3.0</td>\n",
       "      <td>-5671972220290336808</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>77</td>\n",
       "      <td>0.654432</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>willimoa/pydal</td>\n",
       "      <td>pydal/dialects/mongo.py</td>\n",
       "      <td>1</td>\n",
       "      <td>22083</td>\n",
       "      <td>import re\\nfrom .._compat import PY2, basestri...</td>\n",
       "      <td>bsd-3-clause</td>\n",
       "      <td>7148857323817256703</td>\n",
       "      <td>34.389423</td>\n",
       "      <td>93</td>\n",
       "      <td>0.518951</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>georgestarcher/TA-SyncKVStore</td>\n",
       "      <td>bin/ta_synckvstore/cloudconnectlib/core/ext.py</td>\n",
       "      <td>1</td>\n",
       "      <td>10300</td>\n",
       "      <td>import calendar\\nimport json\\nimport re\\nimpor...</td>\n",
       "      <td>mit</td>\n",
       "      <td>-2116068727318744484</td>\n",
       "      <td>29.654762</td>\n",
       "      <td>80</td>\n",
       "      <td>0.593495</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>nabucosound/django-propaganda</td>\n",
       "      <td>propaganda/migrations/0001_initial.py</td>\n",
       "      <td>1</td>\n",
       "      <td>2828</td>\n",
       "      <td># -*- coding: utf-8 -*-\\nfrom __future__ impor...</td>\n",
       "      <td>bsd-3-clause</td>\n",
       "      <td>2285667758777388556</td>\n",
       "      <td>38.830986</td>\n",
       "      <td>114</td>\n",
       "      <td>0.541372</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>znuxor/aoc2016</td>\n",
       "      <td>4.py</td>\n",
       "      <td>1</td>\n",
       "      <td>41871</td>\n",
       "      <td>#!/usr/bin/python3\\nimport operator\\n\\n# room ...</td>\n",
       "      <td>bsd-3-clause</td>\n",
       "      <td>-2104829268388077325</td>\n",
       "      <td>40.662687</td>\n",
       "      <td>118</td>\n",
       "      <td>0.834659</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>sharadagarwal/autorest</td>\n",
       "      <td>AutoRest/Generators/Python/Python.Tests/Expect...</td>\n",
       "      <td>1</td>\n",
       "      <td>5365</td>\n",
       "      <td># coding=utf-8\\n# ----------------------------...</td>\n",
       "      <td>mit</td>\n",
       "      <td>-2646046330546511516</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>110</td>\n",
       "      <td>0.630009</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>DeathSurvivorDE/dhbw_schreitbagger</td>\n",
       "      <td>Schreitbagger/Bagger_GUI_v0-0-0-3_st.py</td>\n",
       "      <td>1</td>\n",
       "      <td>8009</td>\n",
       "      <td>\\n'''\\nBagger_GUI v0.0.0.1\\n\\nGrafische Benutz...</td>\n",
       "      <td>gpl-3.0</td>\n",
       "      <td>54990144954214641</td>\n",
       "      <td>54.020690</td>\n",
       "      <td>212</td>\n",
       "      <td>0.507145</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo_name  \\\n",
       "0                    jalavik/inspire-next   \n",
       "1                  dlzhangxg/cloud-ml-sdk   \n",
       "2                          openstack/heat   \n",
       "3                          imapp-pl/golem   \n",
       "4                          willimoa/pydal   \n",
       "...                                   ...   \n",
       "99995       georgestarcher/TA-SyncKVStore   \n",
       "99996       nabucosound/django-propaganda   \n",
       "99997                      znuxor/aoc2016   \n",
       "99998              sharadagarwal/autorest   \n",
       "99999  DeathSurvivorDE/dhbw_schreitbagger   \n",
       "\n",
       "                                                    path  copies   size  \\\n",
       "0                                               setup.py       1   4558   \n",
       "1           cloud_ml_samples/keras/mnist/trainer/task.py       1   2967   \n",
       "2                                 heat/engine/support.py       1   2683   \n",
       "3             tests/golem/network/test_golem_protocol.py       1   1444   \n",
       "4                                pydal/dialects/mongo.py       1  22083   \n",
       "...                                                  ...     ...    ...   \n",
       "99995     bin/ta_synckvstore/cloudconnectlib/core/ext.py       1  10300   \n",
       "99996              propaganda/migrations/0001_initial.py       1   2828   \n",
       "99997                                               4.py       1  41871   \n",
       "99998  AutoRest/Generators/Python/Python.Tests/Expect...       1   5365   \n",
       "99999            Schreitbagger/Bagger_GUI_v0-0-0-3_st.py       1   8009   \n",
       "\n",
       "                                                 content       license  \\\n",
       "0      # -*- coding: utf-8 -*-\\n#\\n# This file is par...       gpl-2.0   \n",
       "1      # Copyright 2017 Xiaomi, Inc.\\n#\\n# Licensed u...    apache-2.0   \n",
       "2      #\\n#    Licensed under the Apache License, Ver...    apache-2.0   \n",
       "3      import unittest\\nfrom devp2p.service import Wi...       gpl-3.0   \n",
       "4      import re\\nfrom .._compat import PY2, basestri...  bsd-3-clause   \n",
       "...                                                  ...           ...   \n",
       "99995  import calendar\\nimport json\\nimport re\\nimpor...           mit   \n",
       "99996  # -*- coding: utf-8 -*-\\nfrom __future__ impor...  bsd-3-clause   \n",
       "99997  #!/usr/bin/python3\\nimport operator\\n\\n# room ...  bsd-3-clause   \n",
       "99998  # coding=utf-8\\n# ----------------------------...           mit   \n",
       "99999  \\n'''\\nBagger_GUI v0.0.0.1\\n\\nGrafische Benutz...       gpl-3.0   \n",
       "\n",
       "                      hash  line_mean  line_max  alpha_frac  autogenerated  \n",
       "0     -4849180608980663294  27.848101        77    0.615840          False  \n",
       "1     -1822461891537938192  30.231579        74    0.649815          False  \n",
       "2     -1815098437948811103  36.788732        78    0.622438          False  \n",
       "3     -5671972220290336808  37.000000        77    0.654432          False  \n",
       "4      7148857323817256703  34.389423        93    0.518951          False  \n",
       "...                    ...        ...       ...         ...            ...  \n",
       "99995 -2116068727318744484  29.654762        80    0.593495          False  \n",
       "99996  2285667758777388556  38.830986       114    0.541372          False  \n",
       "99997 -2104829268388077325  40.662687       118    0.834659          False  \n",
       "99998 -2646046330546511516  35.250000       110    0.630009          False  \n",
       "99999    54990144954214641  54.020690       212    0.507145          False  \n",
       "\n",
       "[100000 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "sample = pd.read_json(files[2], lines=True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/usr/bin/env python\\n\\n# Copyright (C) 2014 Aldebaran Robotics\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \"AS IS\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n#\\n#import ROS dependencies\\nimport rospy\\n\\n#import NAO dependencies\\nfrom naoqi_driver.naoqi_node import NaoqiNode\\nfrom geometry_msgs.msg import PoseStamped\\nfrom geometry_msgs.msg import Pose\\nimport almath\\nimport tf\\nfrom tf.transformations import euler_from_quaternion\\n\\nclass MoveToListener(NaoqiNode):\\n\\n    def __init__(self):\\n        NaoqiNode.__init__(self, \\'naoqi_moveto_listener\\')\\n        self.connectNaoQi()\\n        self.listener = tf.TransformListener()\\n\\n        self.subscriber = rospy.Subscriber(\"/move_base_simple/goal\", PoseStamped, self.callback)\\n\\n    # (re-) connect to NaoQI:\\n    def connectNaoQi(self):\\n        rospy.loginfo(\"Connecting to NaoQi at %s:%d\", self.pip, self.pport)\\n\\n        self.motionProxy = self.get_proxy(\"ALMotion\")\\n        if self.motionProxy is None:\\n            exit(1)\\n\\n    def callback(self, poseStamped):\\n        # reset timestamp because of bug: https://github.com/ros/geometry/issues/82\\n        poseStamped.header.stamp = rospy.Time(0)\\n        try:\\n            robotToTarget1 = self.listener.transformPose(\"/base_footprint\", poseStamped)\\n        except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException) as e:\\n            rospy.logerr(\"Error while transforming pose: %s\", str(e))\\n            return\\n        quat = robotToTarget1.pose.orientation\\n        (roll,pitch,yaw) = euler_from_quaternion((quat.x, quat.y, quat.z, quat.w))\\n        self.motionProxy.moveTo(robotToTarget1.pose.position.x, robotToTarget1.pose.position.y, yaw)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.content[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo usado por OpenAI, Codex, est√° basado en la arquitectura [GPT](https://paperswithcode.com/method/gpt) y contiene 12 billones de par√°metros. Esto est√° un poco fuera de nuestra alcance (de momento üòù) as√≠ que usaremos la implementaci√≥n de Karpathy, [minGPT](https://github.com/karpathy/minGPT), que nos permite entrenar peque√±os transformers basados en la arquitectura GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit one sample con funci√≥n def sum(a, b): return a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit one batch del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train Codex using the same learning rate as the corresponding GPT model, with a 175 step linear warmup and\n",
    "cosine learning rate decay. We train for a total of 100 billion\n",
    "tokens, using the Adam optimizer with Œ≤1 = 0.9, Œ≤2 = 0.95, eps = 10‚àí8, and a weight decay coefficient of 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejoras: usar tokenizer pre-entrenado (gpt3), usar modelo m√°s grande, ...\n",
    "Next: meter en una api (por ejemplo heroku), hacer vscode extension, ..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
