{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/076_pbdl_jax_cfd_intro/076_pbdl_jax_cfd_intro.ipynb)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PBDL con JAX para CFD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Este es el primero en una serie de posts con un triple objetivo de aprendizaje, lo que significa aprender tres cosas a la vez 游뱚 (el tiempo es limitado y hay que optimizar). Seg칰n el orden en el que aparecen en el t칤tulo:\n",
    "\n",
    "- [**PBDL**](https://physicsbaseddeeplearning.org/intro.html): *Physics-Based Deep Learning*, o el uso del *Deep Learning* (redes neuronales) para simulaci칩n f칤sica. \n",
    "- [**JAX**](https://github.com/google/jax): Una librer칤a para computaci칩n num칠rica, con especial 칠nfasis en Inteligencia Artificial.\n",
    "- [**CFD**](https://es.wikipedia.org/wiki/Mec%C3%A1nica_de_fluidos_computacional): *Computational Fluid Dynamics*, el campo de la f칤sica que se enfoca en la simulaci칩n de fluidos para aplicaciones de aerodin치mica, combusti칩n, etc.\n",
    "\n",
    "Si te interesa aprender sobre cualquiera de estos tres temas (los cuales por si solos merecen de gran atenci칩n), estas en el lugar adecuado 游뗶 Sin embargo, te advierto que nos vamos a alejar del *machine learning* tradicional para explorar un nuevo campo, el del uso de las redes neuronales para aproximar soluciones a ecuaciones diferenciales. Es posible que en algunos momentos te preguntes: 쯘s esto realmente *machine learning*? Te entiendo. A칰n as칤, creo firmemente que el campo del *PBDL* revolucionar치 la manera en la que simulamos la naturaleza en los pr칩ximos a침os, de la misma manera que el *Deep Learning* ha revolucionado (y lo sigue haciendo) tantos otros campos de la ciencia, como por ejemplo el [plegado de proteinas](https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Physics-based Deep Learning*\n",
    "\n",
    "El campo del *PBDL* es una disciplina relativamente nueva e inexplorada que se basa el uso de redes neuronales para sustituir (o complementar) m칠todos num칠ricos \"tradicionales\" utilizados desde hace a침os para simular los diferentes procesos f칤sicos que rigen nuestra naturaleza (desde el comportamiento de nuestra atm칩sfera hasta el movimiento de estrellas y galaxias). Estos procesos pueden ser descritos, en la mayor칤a de ocasiones, mediante ecuaciones matem치ticas. Resolver estas ecuaciones nos permite calcular, por ejemplo, la distribuci칩n de presi칩n sobre una superficie aerodin치mica (lo cual es muy 칰til a la hora de dise침ar aviones m치s eficientes, entre muchas otras aplicaciones). Sin embargo, como te podr치s imaginar, estas ecuaciones suelen ser muy dif칤ciles de resolver y, en la mayor칤a de situaciones, ni siquiera pueden ser resueltas de manera anal칤tica. Es aqu칤 donde entran en juego los m칠todos num칠ricos, t칠cnicas que nos permiten aproximar soluciones a estas ecuaciones que si bien no son exactas son lo suficientemente precisas para su uso en aplicaciones reales. Tradicionalmente, m칠todos num칠ricos de este estilo requieren de grandes recursos computacionales (es por este motivo que tenemos \"superordenadores\"). Por lo que cualquier avance en el campo que nos permita encontrar soluciones m치s r치pidas y baratas supone una revoluci칩n. Creo que el campo del *PBDL* ser치 la siguiente revoluci칩n en este campo. De hecho, este fue el motivo por el que me adentr칠 en el mundo del *Deep Learning*, persiguiendo la idea de que usar [redes neuronales para aproximar soluciones a ecuaciones diferenciales](https://arxiv.org/abs/1912.04737) pod칤a ser una buena idea.\n",
    "\n",
    "> Recientemente se ha publicado este [libro](https://physicsbaseddeeplearning.org/intro.html) sobre *PBDL*. No dudes en consultarlo para aprender m치s !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Computational Fluid Dynamics*\n",
    "\n",
    "Dentro del gran abanico de aplicaciones de la f칤sica computacional, la mec치nica de fluidos computacional se encarga del estudio del comportamiento de fluidos, principalmente mediante la resoluci칩n de las ecuaciones de [Navier-Stokes](https://es.wikipedia.org/wiki/Ecuaciones_de_Navier-Stokes). Esto tiene un uso muy importante en el dise침o de aeronaves, coches (muy importante en coches el칠ctricos), previsi칩n meteorol칩gica y an치lisis de la evoluci칩n de contaminantes, etc. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/X-43A_%28Hyper_-_X%29_Mach_7_computational_fluid_dynamic_%28CFD%29.jpg/1024px-X-43A_%28Hyper_-_X%29_Mach_7_computational_fluid_dynamic_%28CFD%29.jpg)\n",
    "\n",
    "Como ya he comentado anteriormente, resolver estas ecuaciones de manera anal칤tica es imposible y su resoluci칩n num칠rica require de grandes recursos computacionales. A칰n as칤, cada vez es m치s extendido su uso. En el caso del sector aeron치utico la alternativa es el uso de t칰neles de viento, lo cual es todav칤a m치s caro y lento. Poder dise침ar veh칤culos con software de dise침o 3d por ordenador, simular su comportamiento en varias condiciones e iterar su dise침o hasta encontrar la geometr칤a 칩ptima en entornos virtuales es una gran ventaja. Creo que el uso del *Deep Learning* para *CFD* supondr치 una revoluci칩n y acelerar치, a la vez que abaratar치, todo este proceso dando como resultado veh칤culos m치s eficientes, que viajen m치s r치pido consumiendo y contaminando menos. \n",
    "\n",
    "> Si quieres aprender m치s sobre *CFD* te recomiendo echarle un vistazo a mi [tesis doctoral](https://www.tesisenred.net/handle/10803/667041#page=1) 游뱅"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## JAX\n",
    "\n",
    "Para explorar el mundo del *PBDL* para *CFD* usaremos la librer칤a [JAX](https://github.com/google/jax). Desarrollada y mantenida por Google, JAX es una librer칤a para c치lculo num칠rico en Python con un enfoque particular en *machine learning*, ya que nos va a permitir calcular derivadas de forma autom치tica y ejecutar nuestras operaciones en GPUs y TPUs de manera sencilla. Similar en esp칤ritu a Tensorflow y Pytorch, la principal diferencia de JAX es su API minimalista y sencilla."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instalaci칩n\n",
    "\n",
    "Para instalar JAX puedes seguir la [instrucciones](https://github.com/google/jax#installation) en Github. La versi칩n en CPU la puedes instalar en Ubuntu, MacOS y Windows. La versi칩n GPU solo la podr치s instalar en Ubuntu, donde necesitar치s tener instalado CUDA y CUDNN. En Google Colab, ya lo tendr치s instalado y listo para ser usado tanto en CPU, GPU y TPU. Una vez instalado, puedes probar que todo est치 bien."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import jax\n",
    "\n",
    "jax.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.2.21'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conceptos b치sicos\n",
    "\n",
    "Lo primero que tienes que saber acerca de JAX es que es muy similar a NumPy, por lo que lo podr치s usar para lo mismo (m치s algunos beneficios que veremos m치s adelante). Uno de los usos principales de NumPy, que usaremos mucho a la hora de simular fluidos y que tambi칠n se usa a la hora de entrenar redes neuronales, es la multiplicaci칩n de matrices. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "# esto es un vector\n",
    "\n",
    "x = jnp.arange(3)\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0, 1, 2], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# esto es una matriz\n",
    "\n",
    "I = jnp.eye(3)\n",
    "I"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[1., 0., 0.],\n",
       "             [0., 1., 0.],\n",
       "             [0., 0., 1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# multiplicaci칩n matriz-vector \n",
    "\n",
    "I @ x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0., 1., 2.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transformaciones\n",
    "\n",
    "El concepto de `transformaciones` es lo que le da a JAX su flexibilidad y potencia. Estos son algunos ejemplos:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "def func(size=1000):\n",
    "  x = jnp.arange(size)\n",
    "  I = jnp.eye(size)\n",
    "  return I @ x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "%timeit func()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "993 췃s 췀 28.4 췃s per loop (mean 췀 std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con `jit` aceleraremos nuestros c치lculos gracias al *just-in-time compiler*."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "from jax import jit\n",
    "\n",
    "func_jit = jit(func)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "%timeit func_jit()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46.5 췃s 췀 374 ns per loop (mean 췀 std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con `grad` podremos calcular derivadas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "def func2(x):\n",
    "  return x**2.\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "x = jnp.arange(3.)\n",
    "\n",
    "func2(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0., 1., 4.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from jax import grad\n",
    "\n",
    "derivative_fn = grad(func2)\n",
    "\n",
    "derivative_fn(10.)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray(20., dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con `vmap` podremos auto-vectorizar nuestro c칩digo, sin tener que preocuparnos por pensar como pasar nuestros c치lculos a modo \"batch\"."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "def func3(x):\n",
    "  I = jnp.eye(x.size)\n",
    "  return I @ x\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "x = jnp.arange(3)\n",
    "\n",
    "func3(x)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([0., 1., 2.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "x_batch = jnp.stack(3*[x])\n",
    "\n",
    "x_batch"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[0, 1, 2],\n",
       "             [0, 1, 2],\n",
       "             [0, 1, 2]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "func3(x_batch) # esto no va porque las dimensiones no encajan"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got [9] and [3].",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33437/764660429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfunc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# esto no va porque las dimensiones no encajan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_33437/2536116267.py\u001b[0m in \u001b[0;36mfunc3\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accepted_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6552\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6553\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6554\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeferring_binary_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision)\u001b[0m\n\u001b[1;32m   4829\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_squeeze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4830\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_squeeze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4831\u001b[0;31m   out = lax.dot_general(\n\u001b[0m\u001b[1;32m   4832\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb_is_mat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4833\u001b[0m     precision=precision)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3435\u001b[0m     msg = (\"dot_general requires contracting dimensions to have the same \"\n\u001b[1;32m   3436\u001b[0m            \"shape, got {} and {}.\")\n\u001b[0;32m-> 3437\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_contracting_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_contracting_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_dot_general_shape_computation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension_numbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got [9] and [3]."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from jax import vmap \n",
    "\n",
    "func_vmap = vmap(func3)\n",
    "\n",
    "func_vmap(x_batch)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DeviceArray([[0., 1., 2.],\n",
       "             [0., 1., 2.],\n",
       "             [0., 1., 2.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Existen otras transformaciones que pueden ser 칰tiles, adem치s las podemos combinar de manera arbitraria. Todo esto lo iremos aprendiendo en posts futuros."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dd3c0ff7553675f8399160a12fbc0c6054e9524c8e841ec60a211865d03cacc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}