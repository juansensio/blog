{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/057_pytorch_lightning/pytorch_lightning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has ido siguiendo los diferentes posts de este blog, es posible que hayas entrenado varias redes neuronales utilizando la librer√≠a `Pytorch`. De ser as√≠, quiz√°s has tenido la sensaci√≥n de estar repitiendo el mismo c√≥digo una y otra vez, sobre todo en lo referente al bucle de entrenamiento. Adem√°s, es posible que hayas tenido problemas intentando implementar funcionalidad m√°s avanzada, asegur√°ndote que todo funciona como deber√≠a sin errores. ¬øNo ser√≠a estupendo tener una librer√≠a que implementase por nosotros todo este c√≥digp *boilerplate* sin perder la flexibilidad que nos ofrece `Pytorch`? Pues est√°s de enhorabuena, porque tal librer√≠a existe, y se llama [Pytorch Lightning](https://www.pytorchlightning.ai) ‚ö°Ô∏è. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.7'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üí° Puedes instalar pythorch lighning con el comando `pip install pytorch-lightning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post aprenderemos los conceptos b√°sicos de esta librer√≠a, entrenando un modelo simple para clasificaci√≥n de im√°genes con el dataset `MNIST` como ya hemos hecho en varios posts anteriores, as√≠ podremos comparar directamente ambas opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos los datos\n",
    "\n",
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ])\n",
    "                      ), batch_size=2048, shuffle=True, pin_memory=True),\n",
    "    'test': torch.utils.data.DataLoader(torchvision.datasets.MNIST('../data', train=False,\n",
    "                   transform=torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])\n",
    "                     ), batch_size=2048, shuffle=False, pin_memory=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar nuestro modelo usando puro `Pytorch`, primero definimos nuestra red neuronal creando una clase que derive de `torch.nn.Module` en la que tenemos que definir la funci√≥n `__init__`, con las diferentes capas del modelo, y `forward`, con todas las operaciones necesarias para calcular las salidas de la red a partir de las entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el modelo\n",
    "\n",
    "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(pk, stride=ps)\n",
    "    )\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self, n_channels=1, n_outputs=10):\n",
    "    super().__init__()\n",
    "    self.conv1 = block(n_channels, 64)\n",
    "    self.conv2 = block(64, 128)\n",
    "    self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos nuestro modelo, necesitamos definir la l√≥gica de entrenamiento. En este paso, `Pytorch` nos da total libertad para hacerlo de la manera en la que queramos. Una opci√≥n que hemos utilizado en posts anteriores es definir una funci√≥n `fit`, a la cual le pasaremos nuestro modelo y datos, y que se encargar√° de todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenamos el modelo\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def fit(model, dataloader, epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss, train_acc = [], []\n",
    "        bar = tqdm(dataloader['train'])\n",
    "        for batch in bar:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "            train_acc.append(acc)\n",
    "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
    "        bar = tqdm(dataloader['test'])\n",
    "        val_loss, val_acc = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                X, y = batch\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                val_loss.append(loss.item())\n",
    "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "                val_acc.append(acc)\n",
    "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
    "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestra funci√≥n `fit` hemos implementado la l√≥gica de entrenamiento y evaluaci√≥n del modelo, el c√°lculo de su precisi√≥n a la vez que imprimimos por pantalla la informaci√≥n m√°s relevante durante el entrenamiento en una barra de progreso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.61840 acc 0.83090: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:07<00:00,  3.79it/s]\n",
      "val_loss 0.20638 val_acc 0.94002: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.56it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss 0.61840 val_loss 0.20638 acc 0.83090 val_acc 0.94002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.14674 acc 0.95707: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:07<00:00,  4.08it/s]\n",
      "val_loss 0.08969 val_acc 0.97255: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.50it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss 0.14674 val_loss 0.08969 acc 0.95707 val_acc 0.97255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.08559 acc 0.97516: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:07<00:00,  4.07it/s]\n",
      "val_loss 0.05989 val_acc 0.98230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.57it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss 0.08559 val_loss 0.05989 acc 0.97516 val_acc 0.98230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.06402 acc 0.98114: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:07<00:00,  4.09it/s]\n",
      "val_loss 0.05274 val_acc 0.98333: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.56it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss 0.06402 val_loss 0.05274 acc 0.98114 val_acc 0.98333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.05296 acc 0.98434: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:07<00:00,  4.08it/s]\n",
      "val_loss 0.04791 val_acc 0.98432: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss 0.05296 val_loss 0.04791 acc 0.98434 val_acc 0.98432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero, ¬øque pasar√≠a si quisi√©semos implementar t√©cnicas como *early stopping* o guardar el mejor modelo durante el entrenamiento ?, ¬øo calcular otras m√©tricas m√°s all√° de la precisi√≥n?, ¬øo entrenar otros modelos m√°s complicados que requieran de bucles m√°s elaborados? En todos estos casos tendr√≠amos que modificar nuestra funci√≥n `fit`, corriendo el riesgo de introducir *bugs*, y resultando en una implementaci√≥n distinta para cada aplicaci√≥n en la que trabajemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El *LightningModule*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar estos problemas, `Pytorch Lightning` nos ofrece la clase `LightningModule`, la cual podemos utilizar para definir nuestros modelos de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(pl.LightningModule):\n",
    "    \n",
    "    # igual que antes\n",
    "    def __init__(self, n_channels=1, n_outputs=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = block(n_channels, 64)\n",
    "        self.conv2 = block(64, 128)\n",
    "        self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
    "    \n",
    "    # igual que antes\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # l√≥gica de entrenamiento\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # no hace falta enviar nada a la gpu\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('loss', loss)\n",
    "        return loss\n",
    "        # no necesitamos llamar a loss.backward() ni optimier.step()\n",
    "        # pytorch lightning se encarga por nosotros\n",
    "\n",
    "    # optimizador\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, las clases `__init__` y `forward` son exactamente iguales que en la implementaci√≥n original. Sin embargo, hemos a√±adido dos nuevas funciones: `training_step`, en la que calculamos la salida de la red y devolvemos la funci√≥n de p√©rdida, y `configure_optimizers`, en la que devolvemos el optimizador. `Pytorch Lightning` se encarga de mover los datos a la *GPU* si es necesario, as√≠ como de llamar a las funciones `loss.backward`, `optimizer.zero_grad` y `optimizer.step`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El *Lightning Trainer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias a la implementaci√≥n aterior, ahora podemos entrenar nuestro modelo de manera sencilla con el *lightning trainer*. Primero, instanciaremos un `trainer` al cual le podemos pasar par√°metros tales como el n√∫mero de epochs. Una vez definido el `trainer`, podemos entrenar nuestro modelo simplemente llamando a su funci√≥n `fit`, pas√°ndole como par√°mteros nuestro modelo y el dataloader de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 640   \n",
      "1 | conv2 | Sequential | 73 K  \n",
      "2 | fc    | Linear     | 62 K  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6ca8e4622340ccaf207eceb96ecb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5)\n",
    "trainer.fit(modelo, dataloader['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pytorch Lightning` nos da informaci√≥n interesante al principio del entrenamiento, como el hardware disponible y usado as√≠ como un resumen de nuestro modelo y su n√∫mero de par√°metros. Cuando empiece el entrenamiento, veremos una barra de progreso indic√°ndonos la epoch en la que nos encontramos y el valor de la funci√≥n de p√©rdida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando en GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las principales ventajas de `Pytorch Lightning` es lo sencillo que es entrenar en diferente *hardware*. Para entrenar nuestro modelo en una *GPU*, simplemente le pasamo la variabale `gpu` al `trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 640   \n",
      "1 | conv2 | Sequential | 73 K  \n",
      "2 | fc    | Linear     | 62 K  \n",
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a440dfdc07d64fb597e099dfe79572b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
    "trainer.fit(modelo, dataloader['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, indicando `gpus=1` entrenaremos nuestro modelo en una *GPU*. Y es que si disponemos de m√°s de una *GPU*, podremos indicar el n√∫mero y `Pytorch Lightning` se encargar√° de distribuir el entrenamiento entre todas ellas üî•. Tambi√©n podremos indicar un n√∫mero de nodos, *GPUs* por nodo e incluso *TPUs*. Todo ello, sin cambiar ni una l√≠nea de c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando datos de validaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar nuestro modelo a la vez que lo entrenamos, simplemente tenemos que definir la funci√≥n `validation_step` en el *LightningModule*. Podemos ver cualquier informaci√≥n en la barra de progreso con la funci√≥n `self.log` con la variable `prog_bar=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, n_channels=1, n_outputs=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = block(n_channels, 64)\n",
    "        self.conv2 = block(64, 128)\n",
    "        self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, pasaremos nuestro dataloader de validaci√≥n tambi√©n en el `trainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 640   \n",
      "1 | conv2 | Sequential | 73 K  \n",
      "2 | fc    | Linear     | 62 K  \n",
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a5b7e5bd464e289402b5a0962b228d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
    "trainer.fit(modelo, dataloader['train'], dataloader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El *LightningDataModule*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que podemos encapsular nuestro modelo y la l√≥gica de entrenamiento directamente en una sola clase, podemos hacer algo similar para nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, path = '../data', batch_size = 64):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.mnist_train = torchvision.datasets.MNIST(\n",
    "            self.path, train=True, download=True, transform=torchvision.transforms.Compose([\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])\n",
    "          )\n",
    "        self.mnist_val = torchvision.datasets.MNIST(\n",
    "            self.path, train=False, download=True, transform=torchvision.transforms.Compose([\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])\n",
    "          )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.mnist_val, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funci√≥n `setup` se encargar√° de descargar los datos y procesarlos como sea necesario para generar los datasets. Despu√©s, utilizaremos las funciones `train_dataloader` y `val_dataloader` para generar los *dataloaders*. Una vez definido el *LightningDataModule*, podemos entrenar nuestro modelo de manera simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | conv1 | Sequential | 640   \n",
      "1 | conv2 | Sequential | 73 K  \n",
      "2 | fc    | Linear     | 62 K  \n",
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8585db176f684c28831be0436c2fc9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "dm = MNISTDataModule()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
    "trainer.fit(modelo, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post hemos aprendido los conceptos b√°sicos de la librer√≠a `Pytorch Lightning`, la cual nos ayudar√° a ser m√°s eficientes a la hora de entrenar modelos en `Pytorch`. En primer lugar, el objeto `LightningModule` reemplaza al objeto `torch.nn.Module` a la hora de definir nuestros modelos. Adem√°s, podremos indicarle la l√≥gica para entrenar y validar nuestro modelo de manera simple. En segundo lugar, el objeto `LightningDataModule` nos permite encapsular la l√≥gica de descarga y preparaci√≥n de los datos. Estas dos clases es lo √∫nico que necesitaremos para llevar todo el proceso a cabo, por lo que nuestro c√≥digo quedar√° mucho m√°s ordenado y tambi√©n ser√° m√°s reproducible. Gracias a estas definiciones, podremos usar el `Lightning Trainer` para entrenar de manera simple nuestro modelo, ya sea en la *CPU* o *GPU* sin tener que hacer ning√∫n cambio en el c√≥digo.\n",
    "\n",
    "Si bien hemos presentado los fundamentos, existe mucha m√°s funcionalidad interesante en la librer√≠a. En pr√≥ximos posts veremos algunos ejemplos, as√≠ como otras librer√≠as que encajan muy bien con `Pytorch Lightning` para optimizar nuestro proceso de trabajo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
