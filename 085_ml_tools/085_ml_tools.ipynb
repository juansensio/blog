{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/blog/blob/master/085_ml_tools/085_ml_tools.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librer√≠as de Python para ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el post anterior arrancamos con la serie sobre `Machine Learning`, en la que veremos m√∫ltiples algoritmos desarrollados durante las √∫ltimas d√©cadas y que podemos usar como alternativa a las `redes neuronales` (*deep learning*), en algunos casos obteniendo mejores resultados (sobretodo en aquellos casos en los que no dispongamos de un dataset grande). Sin embargo, antes de entrar con los algoritmos y aplicaciones, vamos a hablar sobre el ecosistema de librer√≠as existentes en `Python` para el `Machine Learning`, haciendo hincapi√© en aquellas m√°s usadas por la comunidad y que tambi√©n utilizaremos en esta serie.\n",
    "\n",
    "![](./tools.png)\n",
    "\n",
    "En la imagen anterior puedes ver un resumen de las herramientas m√°s usadas a d√≠a de hoy para `Machine Learning` con `Python`. Las herramientas rodeadas por un c√≠rculo rojo son las que usaremos en esta serie, en verde son herramientas para `deep learning` que no usaremos (pero hemos usado en otros posts). Las herramientas sin c√≠rculo no las usaremos, pero vale la pena conocerlas ya que pueden serte √∫tiles para algunas aplicaciones. \n",
    "\n",
    "En la base podemos encontrar `Python`, el lenguaje de programaci√≥n base que todas las herramientas utilizan. Por encima encontramos herramientas como `Numpy`, para c√°lculo num√©rico, o `Jupyter`, para ejecutar nuestro c√≥digo en `notebooks`. Por encima vemos herramientas basadas en `Numpy` como `Pandas`, para trabajar con datos tabulares, y `Matplotlib`, para generar gr√°ficos en `Python`. Finalmente, en la √∫ltima capa, encontramos `Scikit-Learn`, una de las librer√≠as m√°s utilizadas hoy en d√≠a para entrenar modelos de `Machine Learning`.\n",
    "\n",
    "> En este blog ya hemos dedicado posts a todas estas librer√≠as, excepto a `Scikit-Learn`. Te recomiendo especialmente, si no conoces estas librer√≠as, mi curso gratuito de [An√°lisis de Datos](https://juansensio.com/da-yt) en las que aprenderas sobre ellas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resto de este post lo vamos a dedicar a introducir los conceptos m√°s importantes de [Scikit-Learn](https://scikit-learn.org/stable/), y que desarrollaremos durante la serie. Puedes empezar por instalar la librer√≠a\n",
    "\n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "Y seguir echando un vistazo a la [documentaci√≥n](https://scikit-learn.org/stable/getting_started.html) y [ejemplos](https://scikit-learn.org/stable/auto_examples/index.html). \n",
    "\n",
    "En cualquier proyecto de `Machine Learning` deberemos seguir una serie de pasos, los cuales describiremos al final de la serie. En lo referente al entrenamiento de modelos, normalmente encontramos tres pasos:\n",
    "\n",
    "1. Preparar los datos\n",
    "2. Entrenar modelos\n",
    "3. Optimizar hyperpar√°metros\n",
    "\n",
    "Existen otros pasos igual o m√°s de importantes, pero (repito) los veremos m√°s adelante ya que no involucran el uso de `Scikit-Learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo vamos a utilizar un dataset para predicci√≥n de precios de casas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "URL = \"https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/housing.tgz\"\n",
    "PATH = \"housing.tgz\"\n",
    "\n",
    "def getData(url=URL, path=PATH):\n",
    "  r = requests.get(url)\n",
    "  with open(path, 'wb') as f:\n",
    "    f.write(r.content)  \n",
    "  housing_tgz = tarfile.open(path)\n",
    "  housing_tgz.extractall()\n",
    "  housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro objetivo ser√° el de predecir la variable `median_house_value` a partir del resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar tenemos variables continuas, categ√≥ricas y algunos *missing values*. Vamos a ver como podemos tratar estos aspectos con `Scikit-Learn`, aunque primero separaremos unas cuantas muestras para entrenar y el resto para evaluar nuestros modelos. Para ello vamos a utilizar la que es la funcionalidad probablemente m√°s utilizada de la librer√≠a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 16512, 4128)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2) # 20% de los datos para test, 80% para entrenamiento\n",
    "\n",
    "len(data), len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "ax.hist(data['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(train['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(test['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42) # siempre tendremos el mismo resultado\n",
    "ax.hist(data['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(train['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(test['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=69, stratify=data['ocean_proximity']) # balancear\n",
    "ax.hist(data['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(train['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "ax.hist(test['ocean_proximity'], bins=len(data['ocean_proximity'].value_counts()))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tratar los *missing values* podemos usar un `Imputer`, que puede ser tan sencillo como cambiar los valores inexistentes por el valor promedio de la columna o un valor fijo hasta el uso de algoritmos m√°s complejos que puedes encontrar en la documentaci√≥n. En este caso solo tenemos una columna con *missing values* (`total_rooms`) de tipo num√©rico, pero si tambi√©n tuvi√©semos *missing values* en variables categ√≥ricas deber√≠amos separarlas ya que querremos usar estrategias diferentes. De hecho, es buena idea separar variables num√©ricas de categ√≥ricas ya que las trataremos de diferente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, y_train = train.drop(['median_house_value'], axis=1), train['median_house_value'].copy()\n",
    "test_data, y_test = test.drop(['median_house_value'], axis=1), test['median_house_value'].copy()\n",
    "\n",
    "train_num = train_data.drop(['ocean_proximity'], axis=1)\n",
    "train_cat = train_data[['ocean_proximity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.5    ,   34.26   ,   29.     , 2127.     ,  434.     ,\n",
       "       1167.5    ,  409.     ,    3.54025])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\") # definir imputer\n",
    "imputer.fit(train_num) # calcular mediana\n",
    "imputer.statistics_ # valores calculado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1764e+02,  3.4040e+01,  2.1000e+01, ...,  2.5560e+03,\n",
       "         4.8400e+02,  2.4716e+00],\n",
       "       [-1.1925e+02,  3.4270e+01,  4.6000e+01, ...,  3.8200e+02,\n",
       "         1.4300e+02,  3.5000e+00],\n",
       "       [-1.1833e+02,  3.3930e+01,  3.8000e+01, ...,  4.1200e+02,\n",
       "         1.1900e+02,  6.0718e+00],\n",
       "       ...,\n",
       "       [-1.1897e+02,  3.5380e+01,  4.2000e+01, ...,  1.0380e+03,\n",
       "         2.9900e+02,  9.9510e-01],\n",
       "       [-1.1934e+02,  3.4390e+01,  2.7000e+01, ...,  3.1400e+02,\n",
       "         1.0600e+02,  2.4659e+00],\n",
       "       [-1.2232e+02,  3.7570e+01,  4.2000e+01, ...,  2.3770e+03,\n",
       "         5.8800e+02,  3.2891e+00]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num = imputer.transform(train_num) # cambiar valores inexistentes por la mediana\n",
    "\n",
    "X_train_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠ observamos el primer patr√≥n que se repetir√° constantemente al trabajar con `Scikit-Learn`, y es el uso de las funciones `fit` y `transform`. La primera la usaremos para calcular todo lo necesario para usar una clase (ya sea un imputer o un modelo) y, en el caso de objetos para procesado de datos, usaremos el `transform` para generar un array de `Numpy` listo para entrenar modelos, llevando a cabo todo el procesado necesario. Otro procesado muy com√∫n, que ayuda a algunos modelos a aprender mejor, es el escalado de los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96771021, -0.74756456, -0.60269331, ...,  1.03927132,\n",
       "        -0.03866464, -0.73393928],\n",
       "       [ 0.16149343, -0.6394833 ,  1.37998002, ..., -0.95584437,\n",
       "        -0.93592799, -0.19795272],\n",
       "       [ 0.62218873, -0.79925559,  0.74552456, ..., -0.92831288,\n",
       "        -0.99907849,  1.14243063],\n",
       "       ...,\n",
       "       [ 0.30170504, -0.11787378,  1.06275229, ..., -0.35382234,\n",
       "        -0.52544974, -1.5034688 ],\n",
       "       [ 0.11642541, -0.58309308, -0.12685171, ..., -1.0182491 ,\n",
       "        -1.03328501, -0.73691003],\n",
       "       [-1.37582676,  0.91124771,  1.06275229, ...,  0.87500006,\n",
       "         0.23498753, -0.30787061]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler # tambi√©n hay min-max, ...\n",
    "\n",
    "scaler = StandardScaler() # mean y std\n",
    "scaler.fit(X_train_num)\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_train_num_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a nuestra columna categ√≥rica, no podremos usarla para entrenar modelos (necesitamos valores num√©ricos). Para ello tenemos que usar un `Encoder`. Adem√°s, como puedes ver, puedes usar la funci√≥n `fit_transform` para llevar a cabo ambas acciones a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "X_train_cat = cat_encoder.fit_transform(train_cat)\n",
    "X_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien podemos llevar a cabo todas las transformaciones que hemos visto una a una, es mucho m√°s pr√°ctico (y reusable) definir `Pipelines`. De esta manera podremos ir desde los datos le√≠do hasta los datos preparados de manera muy sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "num_attribs = list(train_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "\t(\"num\", num_pipeline, num_attribs),\n",
    "\t(\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96771021, -0.74756456, -0.60269331, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.16149343, -0.6394833 ,  1.37998002, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.62218873, -0.79925559,  0.74552456, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.30170504, -0.11787378,  1.06275229, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.11642541, -0.58309308, -0.12685171, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.37582676,  0.91124771,  1.06275229, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = full_pipeline.fit_transform(train_data)\n",
    "\n",
    "X_train # contiene las variables num√©ricas y categ√≥ricas, sin missing values y todo escalado y codificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07386178,  0.54941047, -0.44407944, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.61718117, -0.73816619,  1.85582162, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5671056 , -0.66297923,  0.58691069, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.70230965, -0.74756456,  1.37998002, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.09790671, -0.73816619, -0.91992104, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.2055698 ,  0.7890689 ,  0.42829682, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = full_pipeline.transform(test_data) # ojo ! aqu√≠ no hacemos fit :) s√≥lo transform\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de `Pipelines` es muy potente, ya que puedes incluir tus modelos tambi√©n y exportarlos en archivos de manera que los puedas compartir o usar en diferentes entornos (por ejemplo, para preparar los datos en producci√≥n de la misma manera que en entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enternando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos preparados, ya estamos listos para entrenar modelos. `Scikit-learn` trae much√≠simos modelos implementados y cada uno necesitar√° unos par√°metros diferentes. En esta serie veremos muchos de estos algoritmos, pero todos ellos implementan una interfaz similar basados, de nuevo, en la funci√≥n `fit` para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez el modelo ha sido entrenado, podemos sacar predicciones con la funci√≥n `predict` (recuerda pasarle los datos preparados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108292.22741445, 379888.92139725, 213135.75783887, ...,\n",
       "       215265.23261004, 122562.39714544, 318906.32084628])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lin_reg.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-Learn` tambi√©n implementa multitud de `m√©tricas` que podemos usar para evaluar nuestros modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71008.96666632878"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "preds = lin_reg.predict(X_test)\n",
    "lin_mse = mean_squared_error(y_test, preds)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar otro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66658.8766081703"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tree_reg.predict(X_test)\n",
    "tree_mse = mean_squared_error(y_test, predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que da un poco mejor ü§ó En futuros posts veremos m√°s modelos y c√≥mo mejorarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizaci√≥n de hyperpar√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entrenar modelos de `Machine Learning` podemos usar multitud de `hyperpar√°mteros`, el conjunto de todos aquellos par√°metros que pueden afectar al entrenamiento del modelo y a su desempe√±o final. La forma m√°s utilizada de optimizaci√≥n de hyperpar√°metros probar muchos y quedarse con los mejores üòù siguiendo diferentes estrategias. Por ejemplo, podemos probar diferentes valores de un conjunto determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "\t# 12 (3√ó4) combinaciones\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "\t# 6 (2√ó3) combinaciones\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# entrenar con 5 folds un total de (12+6)*5=90 entrenamientos\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=6, n_estimators=30, random_state=42)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63339.55618309705 {'max_features': 2, 'n_estimators': 3}\n",
      "55291.09598702181 {'max_features': 2, 'n_estimators': 10}\n",
      "52587.09831900864 {'max_features': 2, 'n_estimators': 30}\n",
      "59951.99892011206 {'max_features': 4, 'n_estimators': 3}\n",
      "52764.16418304784 {'max_features': 4, 'n_estimators': 10}\n",
      "50280.79794899106 {'max_features': 4, 'n_estimators': 30}\n",
      "58646.287306317055 {'max_features': 6, 'n_estimators': 3}\n",
      "51933.65975704695 {'max_features': 6, 'n_estimators': 10}\n",
      "49723.11534451858 {'max_features': 6, 'n_estimators': 30}\n",
      "58639.440267951104 {'max_features': 8, 'n_estimators': 3}\n",
      "51947.43577366441 {'max_features': 8, 'n_estimators': 10}\n",
      "49959.65853502058 {'max_features': 8, 'n_estimators': 30}\n",
      "62660.85578333314 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "53682.43657349913 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "60016.802813202616 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "53224.05340560518 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "58561.732410130135 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51914.87547403448 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49214.84552444808"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "preds = best_model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, preds)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este post hemos visto las herramientas m√°s usadas en el ecosistema `Python` para `Machine Learning`. Herramientas como `Python`, `Numpy`, `Pandas` o `Matplotlib` ya las hemos visto en posts anteriores. Aqu√≠, nos hemos centrado en la librer√≠a `Scikit-Learn`, probablemente la m√°s usada a d√≠a de hoy para entrenar modelos de ML en `Python`. Hemos visto como podemos usar la funcionalidad de la librer√≠a para preparar nuestros datos, creando `Pipelines` reutilizables, entrenar modelos y optimizar sus hyperpar√°metros para obtener los mejores modelos posibles. En los siguientes posts entraremos en detalle en diferentes modelos que encontramos en la librer√≠a con ejemplos de aplicaci√≥n."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74dbfc52f168b3071122cf9c0781887d6121c12f9c1b29bca56ce221bccb2a07"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
